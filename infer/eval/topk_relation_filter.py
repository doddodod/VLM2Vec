"""
è¯„ä¼°åœºæ™¯å›¾å…³ç³»é¢„æµ‹ç»“æœçš„è„šæœ¬
ç”¨äºåˆ†æ predict_scene_graph_recall.py è¾“å‡ºçš„ JSON æ–‡ä»¶
æ–°ä»»åŠ¡ï¼šç»Ÿè®¡top50å’Œtop100ä¸­pairç¡®å®å­˜åœ¨äºGTä¸­çš„å¬å›ç‡ä»¥åŠæ··æ·†çŸ©é˜µ
æ›´æ–°ï¼šä½¿ç”¨å®Œæ•´çš„GTæ•°æ®ä½œä¸ºåˆ†æ¯ï¼Œè¯„ä¼°çœŸå®çš„å¬å›ç‡
"""

import json
import argparse
from collections import defaultdict
import numpy as np
from typing import Dict, List, Tuple, Set

try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    HAS_PLOTTING = True
except ImportError:
    HAS_PLOTTING = False


def load_results(json_path: str) -> Dict:
    """åŠ è½½é¢„æµ‹ç»“æœJSONæ–‡ä»¶"""
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data


def load_gt_data(gt_file: str) -> Tuple[Dict, Dict]:
    """
    ä»GTæ–‡ä»¶ä¸­åŠ è½½æ‰€æœ‰GT pairä»¥åŠæ¯å¼ å›¾ç‰‡çš„ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        gt_file: GTæ–‡ä»¶è·¯å¾„
        
    Returns:
        tuple: (gt_pairs_per_image, image_stats)
        - gt_pairs_per_image: å­—å…¸ï¼Œkeyä¸ºimage_idï¼Œvalueä¸ºè¯¥å›¾ç‰‡çš„æ‰€æœ‰GT pairé›†åˆ
          GT pairæ ¼å¼: (subject_class, object_class) - åªçœ‹subject-objectå¯¹ï¼Œä¸è€ƒè™‘predicate
        - image_stats: å­—å…¸ï¼Œkeyä¸ºimage_idï¼Œvalueä¸º{'num_objects': int, 'num_relations': int}
    """
    with open(gt_file, 'r', encoding='utf-8') as f:
        gt_data = json.load(f)
    
    gt_pairs_per_image = {}
    image_stats = {}
    
    for item in gt_data:
        image_id = item['image_id']
        objects = {obj['id']: obj['class_name'] for obj in item['objects']}
        relations = item['relations']
        
        # ç»Ÿè®¡å®ä½“æ•°é‡å’Œå…³ç³»æ•°é‡
        num_objects = len(objects)
        num_relations = len(relations)
        image_stats[image_id] = {
            'num_objects': num_objects,
            'num_relations': num_relations
        }
        
        # æ„å»ºè¯¥å›¾ç‰‡çš„æ‰€æœ‰GT pairï¼ˆåªçœ‹subject-objectå¯¹ï¼Œä¸è€ƒè™‘predicateï¼‰
        gt_pairs = set()
        for rel in relations:
            subject_id = rel['subject_id']
            object_id = rel['object_id']
            
            if subject_id in objects and object_id in objects:
                subject_class = objects[subject_id]
                object_class = objects[object_id]
                # åªä½¿ç”¨ (subject, object) ä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œä¸è€ƒè™‘predicate
                gt_pairs.add((subject_class, object_class))
        
        gt_pairs_per_image[image_id] = gt_pairs
    
    return gt_pairs_per_image, image_stats


def get_per_image_candidates(data: Dict) -> Dict:
    """
    è·å–æŒ‰å›¾ç‰‡åˆ†ç»„çš„å€™é€‰åˆ—è¡¨
    
    Returns:
        å­—å…¸ï¼Œkeyä¸ºimage_idï¼Œvalueä¸ºè¯¥å›¾ç‰‡çš„æ‰€æœ‰å€™é€‰åˆ—è¡¨
    """
    per_image_candidates = {}
    
    if 'per_image_top100_candidates' in data:
        per_image_candidates = data['per_image_top100_candidates']
    elif 'all_candidates' in data:
        all_candidates = data['all_candidates']
        # æŒ‰ image_id åˆ†ç»„
        per_image_candidates_list = defaultdict(list)
        for cand in all_candidates:
            per_image_candidates_list[cand['image_id']].append(cand)
        per_image_candidates = dict(per_image_candidates_list)
    else:
        print("âš ï¸  JSONä¸­æ²¡æœ‰ä¿å­˜å€™é€‰åˆ—è¡¨")
        return None
    
    return per_image_candidates


def calculate_candidate_pair_statistics(data: Dict, gt_pairs_per_image: Dict = None) -> Dict:
    """
    ç»Ÿè®¡æ‰€æœ‰å€™é€‰ä¸­pairçš„æƒ…å†µï¼ˆæœ‰GT vs æ²¡æœ‰GTï¼‰
    
    Args:
        data: é¢„æµ‹ç»“æœæ•°æ®
        gt_pairs_per_image: æ¯å¼ å›¾ç‰‡çš„å®Œæ•´GT pairé›†åˆ
        
    Returns:
        åŒ…å«ç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸
    """
    per_image_candidates = get_per_image_candidates(data)
    if per_image_candidates is None:
        return None
    
    # ç»Ÿè®¡æ‰€æœ‰å€™é€‰ä¸­çš„pair
    all_candidate_pairs = set()  # æ‰€æœ‰å€™é€‰ä¸­çš„pairï¼ˆå»é‡ï¼‰
    # è®°å½•æ¯ä¸ªpairåœ¨å“ªäº›å›¾ç‰‡ä¸­æœ‰GTï¼Œå“ªäº›å›¾ç‰‡ä¸­æ²¡æœ‰GT
    pair_gt_status = defaultdict(lambda: {'has_gt_in_images': set(), 'no_gt_in_images': set()})
    
    # æŒ‰å›¾ç‰‡ç»Ÿè®¡
    per_image_stats = []
    
    for image_id_str, candidates in per_image_candidates.items():
        # ç»Ÿä¸€image_idç±»å‹ï¼ˆè½¬æ¢ä¸ºæ•´æ•°ï¼‰
        try:
            image_id = int(image_id_str)
        except (ValueError, TypeError):
            image_id = image_id_str
        
        # è·å–å®Œæ•´çš„GT pairé›†åˆï¼ˆå¦‚æœæä¾›ï¼‰
        full_gt_pairs = None
        if gt_pairs_per_image:
            full_gt_pairs = gt_pairs_per_image.get(image_id, set())
        
        # ç»Ÿè®¡å½“å‰å›¾ç‰‡çš„å€™é€‰pair
        image_candidate_pairs = set()
        image_pairs_with_gt = set()
        image_pairs_without_gt = set()
        
        for cand in candidates:
            # è¿‡æ»¤æ‰no relationçš„é¢„æµ‹
            if cand.get('predicted_predicate') == 'no relation':
                continue
            
            subject = cand.get('subject', '')
            object_name = cand.get('object', '')
            
            if not subject or not object_name:
                continue
            
            pair_key = (subject, object_name)
            image_candidate_pairs.add(pair_key)
            all_candidate_pairs.add(pair_key)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰GTï¼ˆé’ˆå¯¹å½“å‰å›¾ç‰‡ï¼‰
            has_gt_in_this_image = False
            if full_gt_pairs is not None:
                # ä½¿ç”¨å®Œæ•´GTæ•°æ®åˆ¤æ–­
                has_gt_in_this_image = pair_key in full_gt_pairs
            else:
                # å¦‚æœæ²¡æœ‰å®Œæ•´GTæ•°æ®ï¼Œä½¿ç”¨å€™é€‰ä¸­çš„has_gtæ ‡è®°
                has_gt = cand.get('has_gt', False)
                has_gt_in_this_image = has_gt and cand.get('relation_idx', -1) >= 0
            
            # è®°å½•å½“å‰å›¾ç‰‡çš„GTçŠ¶æ€
            if has_gt_in_this_image:
                image_pairs_with_gt.add(pair_key)
                pair_gt_status[pair_key]['has_gt_in_images'].add(image_id)
            else:
                image_pairs_without_gt.add(pair_key)
                pair_gt_status[pair_key]['no_gt_in_images'].add(image_id)
        
        # è®°å½•æ¯å¼ å›¾ç‰‡çš„ç»Ÿè®¡
        per_image_stats.append({
            'image_id': image_id,
            'total_candidate_pairs': len(image_candidate_pairs),
            'pairs_with_gt': len(image_pairs_with_gt),
            'pairs_without_gt': len(image_pairs_without_gt)
        })
    
    # ç»Ÿè®¡å…¨å±€ï¼šå¦‚æœpairåœ¨è‡³å°‘ä¸€å¼ å›¾ç‰‡ä¸­æœ‰GTï¼Œå°±ç®—æœ‰GTï¼›å¦åˆ™ç®—æ²¡æœ‰GT
    pairs_with_gt = set()
    pairs_without_gt = set()
    
    for pair_key, status in pair_gt_status.items():
        if len(status['has_gt_in_images']) > 0:
            # åœ¨è‡³å°‘ä¸€å¼ å›¾ç‰‡ä¸­æœ‰GTï¼Œç®—ä½œæœ‰GT
            pairs_with_gt.add(pair_key)
        else:
            # åœ¨æ‰€æœ‰å›¾ç‰‡ä¸­éƒ½æ²¡æœ‰GTï¼Œç®—ä½œæ²¡æœ‰GT
            pairs_without_gt.add(pair_key)
    
    total_candidate_pairs = len(all_candidate_pairs)  # å…¨å±€å»é‡åçš„æ€»æ•°
    total_pairs_with_gt = len(pairs_with_gt)
    total_pairs_without_gt = len(pairs_without_gt)
    
    # è®¡ç®—æ‰€æœ‰å›¾ç‰‡å€™é€‰pairæ•°é‡çš„æ€»å’Œï¼ˆæœªå»é‡ï¼Œç”¨äºå¯¹æ¯”ï¼‰
    total_candidate_pairs_sum = sum(stat['total_candidate_pairs'] for stat in per_image_stats)
    
    # è®¡ç®—æ¯”ä¾‹
    ratio_with_gt = total_pairs_with_gt / total_candidate_pairs if total_candidate_pairs > 0 else 0.0
    ratio_without_gt = total_pairs_without_gt / total_candidate_pairs if total_candidate_pairs > 0 else 0.0
    
    stats = {
        'total_candidate_pairs': total_candidate_pairs,  # å…¨å±€å»é‡åçš„æ€»æ•°
        'total_candidate_pairs_sum': total_candidate_pairs_sum,  # æ‰€æœ‰å›¾ç‰‡å€™é€‰pairæ•°é‡çš„æ€»å’Œï¼ˆæœªå»é‡ï¼‰
        'pairs_with_gt': total_pairs_with_gt,
        'pairs_without_gt': total_pairs_without_gt,
        'ratio_with_gt': ratio_with_gt,
        'ratio_without_gt': ratio_without_gt,
        'per_image_stats': per_image_stats
    }
    
    return stats


def calculate_recall_at_k(data: Dict, gt_pairs_per_image: Dict = None, image_stats: Dict = None, k_values: List[int] = [50, 100]) -> Dict:
    """
    è®¡ç®—top50å’Œtop100ä¸­pairç¡®å®å­˜åœ¨äºGTä¸­çš„å¬å›ç‡
    
    Args:
        data: é¢„æµ‹ç»“æœæ•°æ®
        gt_pairs_per_image: æ¯å¼ å›¾ç‰‡çš„å®Œæ•´GT pairé›†åˆï¼ˆå¦‚æœæä¾›ï¼Œä½¿ç”¨å®Œæ•´GTä½œä¸ºåˆ†æ¯ï¼‰
        k_values: Kå€¼åˆ—è¡¨ï¼Œé»˜è®¤[50, 100]
    
    Returns:
        åŒ…å«å¬å›ç‡ç»Ÿè®¡çš„å­—å…¸
    """
    # é™é»˜è®¡ç®—ï¼Œåªåœ¨æœ€åè¾“å‡ºç»“æœ
    
    per_image_candidates = get_per_image_candidates(data)
    if per_image_candidates is None:
        return None
    
    results = {}
    
    for k in k_values:
        
        total_gt_pairs = 0  # æ‰€æœ‰GTä¸­çš„pairæ€»æ•°ï¼ˆå®Œæ•´GTæˆ–å€™é€‰åˆ—è¡¨ä¸­çš„ï¼‰
        total_recalled_pairs = 0  # åœ¨top-kä¸­è¢«å¬å›çš„pairæ•°
        total_gt_pairs_in_candidates = 0  # åœ¨å€™é€‰åˆ—è¡¨ä¸­çš„GT pairæ•°ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        
        # ç”¨äºç»Ÿè®¡æ¯å¼ å›¾ç‰‡çš„æƒ…å†µ
        image_recalls = []
        image_recalls_in_candidates = []  # åŸºäºå€™é€‰åˆ—è¡¨ä¸­çš„GT pairçš„å¬å›ç‡ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        # ç”¨äºç»Ÿè®¡ä¸åŒå®ä½“æ•°é‡å’Œå…³ç³»æ•°é‡çš„å¬å›ç‡åˆ†å¸ƒï¼ˆæ¯ä¸ªkå€¼é‡ç½®ï¼‰
        image_recall_details = []  # æ¯å¼ å›¾ç‰‡çš„è¯¦ç»†ä¿¡æ¯: (image_id, num_objects, num_relations, recall)
        
        for image_id_str, candidates in per_image_candidates.items():
            # ç»Ÿä¸€image_idç±»å‹ï¼ˆè½¬æ¢ä¸ºæ•´æ•°ï¼‰
            try:
                image_id = int(image_id_str)
            except (ValueError, TypeError):
                image_id = image_id_str
            
            # è·å–å®Œæ•´çš„GT pairé›†åˆï¼ˆå¦‚æœæä¾›ï¼‰
            full_gt_pairs = None
            if gt_pairs_per_image:
                full_gt_pairs = gt_pairs_per_image.get(image_id, set())
                if len(full_gt_pairs) == 0:
                    continue
            
            # è·å–å€™é€‰åˆ—è¡¨ä¸­çš„GT pairé›†åˆï¼ˆç”¨äºå¯¹æ¯”ï¼Œåªçœ‹subject-objectå¯¹ï¼‰
            gt_pairs_in_candidates = set()
            for cand in candidates:
                has_gt = cand.get('has_gt', False)
                if has_gt and cand.get('relation_idx', -1) >= 0:
                    subject = cand.get('subject', '')
                    object_name = cand.get('object', '')
                    if subject and object_name:
                        # åªä½¿ç”¨ (subject, object) ä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œä¸è€ƒè™‘predicate
                        gt_pairs_in_candidates.add((subject, object_name))
            
            # å¦‚æœæ²¡æœ‰æä¾›å®Œæ•´GTæ•°æ®ï¼Œä½¿ç”¨å€™é€‰åˆ—è¡¨ä¸­çš„GT pair
            if not gt_pairs_per_image:
                if len(gt_pairs_in_candidates) == 0:
                    continue
                full_gt_pairs = gt_pairs_in_candidates
            
            # è¿‡æ»¤æ‰no relationçš„é¢„æµ‹
            non_bg_candidates = []
            for cand in candidates:
                if cand.get('predicted_predicate') != 'no relation':
                    non_bg_candidates.append(cand)
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œå–top-k
            sorted_candidates = sorted(non_bg_candidates, key=lambda x: x['similarity'], reverse=True)
            top_k = sorted_candidates[:min(k, len(sorted_candidates))]
            
            # ç»Ÿè®¡åœ¨top-kä¸­ç¡®å®å­˜åœ¨äºå®Œæ•´GTä¸­çš„pairï¼ˆåªçœ‹subject-objectå¯¹ï¼‰
            recalled_pairs = set()
            for cand in top_k:
                subject = cand.get('subject', '')
                object_name = cand.get('object', '')
                
                if subject and object_name:
                    # åªä½¿ç”¨ (subject, object) ä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œä¸è€ƒè™‘predicate
                    pair_key = (subject, object_name)
                    if pair_key in full_gt_pairs:
                        recalled_pairs.add(pair_key)
            
            # è®¡ç®—åŸºäºå®Œæ•´GTçš„å¬å›ç‡
            recalled_count = len(recalled_pairs)
            gt_count = len(full_gt_pairs)
            recall = recalled_count / gt_count if gt_count > 0 else 0.0
            
            image_recalls.append(recall)
            total_gt_pairs += gt_count
            total_recalled_pairs += recalled_count
            
            # è®°å½•æ¯å¼ å›¾ç‰‡çš„è¯¦ç»†ä¿¡æ¯ï¼ˆç”¨äºåˆ†å¸ƒç»Ÿè®¡ï¼‰
            if image_stats:
                stats = image_stats.get(image_id, {})
                num_objects = stats.get('num_objects', 0)
                num_relations = stats.get('num_relations', 0)
                image_recall_details.append({
                    'image_id': image_id,
                    'num_objects': num_objects,
                    'num_relations': num_relations,
                    'recall': recall,
                    'recalled_pairs': recalled_count,
                    'total_gt_pairs': gt_count
                })
            
            # è®¡ç®—åŸºäºå€™é€‰åˆ—è¡¨ä¸­GT pairçš„å¬å›ç‡ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
            if gt_pairs_per_image and len(gt_pairs_in_candidates) > 0:
                recalled_in_candidates = len(recalled_pairs & gt_pairs_in_candidates)
                gt_in_candidates_count = len(gt_pairs_in_candidates)
                recall_in_candidates = recalled_in_candidates / gt_in_candidates_count if gt_in_candidates_count > 0 else 0.0
                image_recalls_in_candidates.append(recall_in_candidates)
                total_gt_pairs_in_candidates += gt_in_candidates_count
        
        # è®¡ç®—å¹³å‡å¬å›ç‡å’Œæ•´ä½“å¬å›ç‡
        avg_recall = np.mean(image_recalls) if image_recalls else 0.0
        overall_recall = total_recalled_pairs / total_gt_pairs if total_gt_pairs > 0 else 0.0
        
        # åŸºäºå€™é€‰åˆ—è¡¨ä¸­çš„GT pairçš„å¬å›ç‡ï¼ˆç”¨äºå¯¹æ¯”ï¼‰
        avg_recall_in_candidates = None
        overall_recall_in_candidates = None
        stage1_coverage = None
        if gt_pairs_per_image and total_gt_pairs_in_candidates > 0:
            avg_recall_in_candidates = np.mean(image_recalls_in_candidates) if image_recalls_in_candidates else 0.0
            overall_recall_in_candidates = total_recalled_pairs / total_gt_pairs_in_candidates if total_gt_pairs_in_candidates > 0 else 0.0
            stage1_coverage = total_gt_pairs_in_candidates / total_gt_pairs if total_gt_pairs > 0 else 0.0
        
        results[f'recall@{k}'] = {
            'avg_recall': avg_recall,
            'overall_recall': overall_recall,
            'total_gt_pairs': total_gt_pairs,  # å®Œæ•´GT pairæ•°
            'total_recalled_pairs': total_recalled_pairs,
            'num_images': len(image_recalls),
            'image_recalls': image_recalls,
            'total_gt_pairs_in_candidates': total_gt_pairs_in_candidates if gt_pairs_per_image else None,
            'avg_recall_in_candidates': avg_recall_in_candidates,
            'overall_recall_in_candidates': overall_recall_in_candidates,
            'stage1_coverage': stage1_coverage,
            'image_recall_details': image_recall_details  # æ¯å¼ å›¾ç‰‡çš„è¯¦ç»†ä¿¡æ¯
        }
        
        # åªåœ¨æœ€åæ€»ç»“æ—¶è¾“å‡º
    
    print()
    return results


def calculate_confusion_matrix(data: Dict, gt_pairs_per_image: Dict = None, k_values: List[int] = [50, 100]) -> Dict:
    """
    è®¡ç®—pairå¬å›çš„äºŒåˆ†ç±»æ··æ·†çŸ©é˜µ
    åªå…³å¿ƒpairï¼ˆsubject-objectå¯¹ï¼‰æ˜¯å¦è¢«å¬å›ï¼Œä¸åŒºåˆ†è°“è¯
    
    Args:
        data: é¢„æµ‹ç»“æœæ•°æ®
        gt_pairs_per_image: æ¯å¼ å›¾ç‰‡çš„å®Œæ•´GT pairé›†åˆï¼ˆå¦‚æœæä¾›ï¼Œä½¿ç”¨å®Œæ•´GTï¼‰
        k_values: Kå€¼åˆ—è¡¨ï¼Œé»˜è®¤[50, 100]
    
    Returns:
        åŒ…å«æ··æ·†çŸ©é˜µçš„å­—å…¸
    """
    # æ··æ·†çŸ©é˜µè®¡ç®—ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸è¾“å‡ºï¼‰
    
    per_image_candidates = get_per_image_candidates(data)
    if per_image_candidates is None:
        return None
    
    results = {}
    
    for k in k_values:
        
        # äºŒåˆ†ç±»æ··æ·†çŸ©é˜µï¼špairæ˜¯å¦è¢«å¬å›
        # TP: GTä¸­çš„pairåœ¨top-kä¸­å‡ºç°äº†
        # FN: GTä¸­çš„pairåœ¨top-kä¸­æ²¡æœ‰å‡ºç°
        # FP: top-kä¸­çš„pairä¸åœ¨GTä¸­
        # TN: top-kä¸­ä¸åœ¨GTä¸­çš„pair
        tp = 0  # True Positive: GTä¸­çš„pairè¢«å¬å›äº†
        fn = 0  # False Negative: GTä¸­çš„pairæ²¡æœ‰è¢«å¬å›
        fp = 0  # False Positive: top-kä¸­çš„pairä¸åœ¨GTä¸­
        tn = 0  # True Negative: top-kä¸­ä¸åœ¨GTä¸­çš„pair
        tn_true = 0  # çœŸæ­£çš„True Negative: ä¸åœ¨GTä¸­ä¸”ä¸åœ¨top-kä¸­çš„pair
        
        # ç»Ÿè®¡pairå‡ºç°æ¬¡æ•°
        gt_pair_occurrences = defaultdict(int)  # GT pairåœ¨top-kä¸­å‡ºç°çš„æ¬¡æ•°ï¼ˆå…¨å±€ç´¯è®¡ï¼‰
        non_gt_pair_occurrences = defaultdict(int)  # éGT pairåœ¨top-kä¸­å‡ºç°çš„æ¬¡æ•°ï¼ˆå…¨å±€ç´¯è®¡ï¼‰
        gt_pair_occurrences_per_image = []  # æ¯å¼ å›¾ç‰‡ä¸­GT pairçš„å¹³å‡å‡ºç°æ¬¡æ•°
        non_gt_pair_occurrences_per_image = []  # æ¯å¼ å›¾ç‰‡ä¸­éGT pairçš„å¹³å‡å‡ºç°æ¬¡æ•°
        
        # æ¯å¼ å›¾ç‰‡å†…çš„æŒ‡æ ‡ç»Ÿè®¡ï¼ˆç”¨äºè®¡ç®—å¹³å‡å€¼ï¼‰
        image_recalls = []  # æ¯å¼ å›¾ç‰‡çš„å¬å›ç‡
        image_precisions = []  # æ¯å¼ å›¾ç‰‡çš„ç²¾ç¡®ç‡
        image_f1s = []  # æ¯å¼ å›¾ç‰‡çš„F1åˆ†æ•°
        image_accuracies = []  # æ¯å¼ å›¾ç‰‡çš„å‡†ç¡®ç‡
        image_specificities = []  # æ¯å¼ å›¾ç‰‡çš„ç‰¹å¼‚æ€§
        
        for image_id_str, candidates in per_image_candidates.items():
            # ç»Ÿä¸€image_idç±»å‹ï¼ˆè½¬æ¢ä¸ºæ•´æ•°ï¼‰
            try:
                image_id = int(image_id_str)
            except (ValueError, TypeError):
                image_id = image_id_str
            
            # è·å–å®Œæ•´çš„GT pairé›†åˆï¼ˆå¦‚æœæä¾›ï¼‰
            full_gt_pairs = None
            if gt_pairs_per_image:
                full_gt_pairs = gt_pairs_per_image.get(image_id, set())
                if len(full_gt_pairs) == 0:
                    continue
            else:
                # å¦‚æœæ²¡æœ‰æä¾›å®Œæ•´GTæ•°æ®ï¼Œä»å€™é€‰åˆ—è¡¨ä¸­ç»Ÿè®¡GT pairï¼ˆåªçœ‹subject-objectå¯¹ï¼‰
                full_gt_pairs = set()
                for cand in candidates:
                    has_gt = cand.get('has_gt', False)
                    if has_gt and cand.get('relation_idx', -1) >= 0:
                        subject = cand.get('subject', '')
                        object_name = cand.get('object', '')
                        if subject and object_name:
                            # åªä½¿ç”¨ (subject, object) ä½œä¸ºå”¯ä¸€æ ‡è¯†ï¼Œä¸è€ƒè™‘predicate
                            full_gt_pairs.add((subject, object_name))
                
                if len(full_gt_pairs) == 0:
                    continue
            
            # è¿‡æ»¤æ‰no relationçš„é¢„æµ‹
            non_bg_candidates = []
            for cand in candidates:
                if cand.get('predicted_predicate') != 'no relation':
                    non_bg_candidates.append(cand)
            
            # ç»Ÿè®¡æ‰€æœ‰å€™é€‰ä¸­çš„pairï¼ˆå»é‡ï¼Œç”¨äºè®¡ç®—çœŸæ­£çš„TNï¼‰
            all_candidate_pairs = set()  # æ‰€æœ‰å€™é€‰ä¸­çš„pairï¼ˆä½¿ç”¨subject-objectå¯¹ä½œä¸ºæ ‡è¯†ï¼‰
            for cand in non_bg_candidates:
                subject = cand.get('subject', '')
                object_name = cand.get('object', '')
                pair_key = (subject, object_name)
                all_candidate_pairs.add(pair_key)
            
            # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œå–top-k
            sorted_candidates = sorted(non_bg_candidates, key=lambda x: x['similarity'], reverse=True)
            top_k = sorted_candidates[:min(k, len(sorted_candidates))]
            
            # ç»Ÿè®¡top-kä¸­å‡ºç°çš„pairï¼ˆåªçœ‹subject-objectå¯¹ï¼‰
            top_k_pairs = set()  # top-kä¸­åœ¨å®Œæ•´GTä¸­çš„pair
            top_k_non_gt_pairs = set()  # top-kä¸­ä¸åœ¨å®Œæ•´GTä¸­çš„pair
            top_k_pair_keys = set()  # top-kä¸­æ‰€æœ‰pairçš„key (subject, object)
            
            # ç»Ÿè®¡å½“å‰å›¾ç‰‡ä¸­pairçš„å‡ºç°æ¬¡æ•°
            image_gt_pair_counts = defaultdict(int)  # å½“å‰å›¾ç‰‡ä¸­GT pairçš„å‡ºç°æ¬¡æ•°
            image_non_gt_pair_counts = defaultdict(int)  # å½“å‰å›¾ç‰‡ä¸­éGT pairçš„å‡ºç°æ¬¡æ•°
            
            for cand in top_k:
                subject = cand.get('subject', '')
                object_name = cand.get('object', '')
                pair_key_so = (subject, object_name)  # subject-objectå¯¹ï¼ˆåªçœ‹è¿™ä¸ªï¼Œä¸è€ƒè™‘predicateï¼‰
                
                if not subject or not object_name:
                    continue
                
                top_k_pair_keys.add(pair_key_so)
                
                if pair_key_so in full_gt_pairs:
                    # åœ¨å®Œæ•´GTä¸­çš„pair
                    top_k_pairs.add(pair_key_so)
                    image_gt_pair_counts[pair_key_so] += 1
                    # å…¨å±€ç»Ÿè®¡ï¼ˆç”¨äºè·¨å›¾ç‰‡ç»Ÿè®¡ï¼‰
                    gt_pair_occurrences[pair_key_so] += 1
                else:
                    # ä¸åœ¨å®Œæ•´GTä¸­çš„pair
                    top_k_non_gt_pairs.add(pair_key_so)
                    image_non_gt_pair_counts[pair_key_so] += 1
                    # å…¨å±€ç»Ÿè®¡ï¼ˆç”¨äºè·¨å›¾ç‰‡ç»Ÿè®¡ï¼‰
                    non_gt_pair_occurrences[pair_key_so] += 1
            
            # è®¡ç®—å½“å‰å›¾ç‰‡çš„å¹³å‡å‡ºç°æ¬¡æ•°
            if len(image_gt_pair_counts) > 0:
                image_avg_gt_occurrences = sum(image_gt_pair_counts.values()) / len(image_gt_pair_counts)
                # ç´¯åŠ åˆ°å…¨å±€ç»Ÿè®¡
                gt_pair_occurrences_per_image.append(image_avg_gt_occurrences)
            
            if len(image_non_gt_pair_counts) > 0:
                image_avg_non_gt_occurrences = sum(image_non_gt_pair_counts.values()) / len(image_non_gt_pair_counts)
                # ç´¯åŠ åˆ°å…¨å±€ç»Ÿè®¡
                non_gt_pair_occurrences_per_image.append(image_avg_non_gt_occurrences)
            
            # è®¡ç®—å½“å‰å›¾ç‰‡çš„TPã€FNã€FPã€TNï¼ˆåŸºäºå®Œæ•´GTï¼‰
            # TP: å®Œæ•´GTä¸­çš„pairåœ¨top-kä¸­å‡ºç°äº†
            image_tp = len(top_k_pairs)
            # FN: å®Œæ•´GTä¸­çš„pairåœ¨top-kä¸­æ²¡æœ‰å‡ºç°
            image_fn = len(full_gt_pairs - top_k_pairs)
            # FP: top-kä¸­çš„pairä¸åœ¨å®Œæ•´GTä¸­
            image_fp = len(top_k_non_gt_pairs)
            # TN: top-kä¸­ä¸åœ¨å®Œæ•´GTä¸­çš„pairï¼ˆè¿™é‡Œç»Ÿè®¡çš„æ˜¯subject-objectå¯¹ï¼‰
            image_tn = len(top_k_non_gt_pairs)
            
            # ç´¯è®¡åˆ°å…¨å±€ç»Ÿè®¡
            tp += image_tp
            fn += image_fn
            fp += image_fp
            tn += image_tn
            
            # è®¡ç®—å½“å‰å›¾ç‰‡çš„æŒ‡æ ‡
            image_total_gt = image_tp + image_fn
            image_total_topk_gt = image_tp + image_fp
            
            image_recall = 0.0
            image_precision = 0.0
            
            if image_total_gt > 0:
                image_recall = image_tp / image_total_gt
                image_recalls.append(image_recall)
            
            if image_total_topk_gt > 0:
                image_precision = image_tp / image_total_topk_gt
                image_precisions.append(image_precision)
            
            # è®¡ç®—F1åˆ†æ•°
            if image_precision > 0 and image_recall > 0:
                image_f1 = 2 * image_precision * image_recall / (image_precision + image_recall)
                image_f1s.append(image_f1)
            
            image_total = image_tp + image_tn + image_fp + image_fn
            if image_total > 0:
                image_accuracy = (image_tp + image_tn) / image_total
                image_accuracies.append(image_accuracy)
            
            if (image_tn + image_fp) > 0:
                image_specificity = image_tn / (image_tn + image_fp)
                image_specificities.append(image_specificity)
            
            # è®¡ç®—çœŸæ­£çš„TNï¼šä¸åœ¨GTä¸­ä¸”ä¸åœ¨top-kä¸­çš„pair
            # æ‰€æœ‰å€™é€‰pairä¸­ä¸åœ¨å®Œæ•´GTä¸­çš„pair
            # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬åªç»Ÿè®¡subject-objectå¯¹ï¼Œä¸è€ƒè™‘è°“è¯
            all_non_gt_pairs = all_candidate_pairs
            # ä¸åœ¨å®Œæ•´GTä¸­ä¸”ä¸åœ¨top-kä¸­çš„pair
            true_tn_pairs = all_non_gt_pairs - top_k_pair_keys
            tn_true += len(true_tn_pairs)
        
        # æ„å»º2x2æ··æ·†çŸ©é˜µ
        #           é¢„æµ‹ä¸ºæ­£ä¾‹(åœ¨top-kä¸­)  é¢„æµ‹ä¸ºè´Ÿä¾‹(ä¸åœ¨top-kä¸­)
        # å®é™…ä¸ºæ­£ä¾‹(åœ¨GTä¸­)    TP              FN
        # å®é™…ä¸ºè´Ÿä¾‹(ä¸åœ¨GTä¸­)  FP              TN
        # æ³¨æ„ï¼šTNç»Ÿè®¡çš„æ˜¯top-kä¸­ä¸åœ¨GTä¸­çš„pairï¼ˆrelation_idx == -1ï¼‰
        # çœŸæ­£çš„TNåº”è¯¥æ˜¯"ä¸åœ¨GTä¸­ä¸”ä¸åœ¨top-kä¸­"ï¼Œä½†æˆ‘ä»¬æ— æ³•ç»Ÿè®¡æ‰€æœ‰å¯èƒ½çš„pair
        cm = np.array([[tp, fn],
                       [fp, tn]])
        
        # è®¡ç®—æŒ‡æ ‡
        total_gt_pairs = tp + fn  # å®Œæ•´GTä¸­çš„pairæ€»æ•°
        total_top_k_pairs = tp  # top-kä¸­åœ¨å®Œæ•´GTä¸­çš„pairæ€»æ•°
        total_top_k_non_gt_pairs = fp  # top-kä¸­ä¸åœ¨å®Œæ•´GTä¸­çš„pairæ€»æ•°
        total_top_k_pairs_all = tp + fp  # top-kä¸­çš„æ€»pairæ•°ï¼ˆTP + FPï¼‰
        
        # è®¡ç®—pairå¹³å‡å‡ºç°æ¬¡æ•°
        # æ–¹å¼1ï¼šè·¨æ‰€æœ‰å›¾ç‰‡çš„å…¨å±€å¹³å‡ï¼ˆæ¯ä¸ªå”¯ä¸€pairåœ¨æ‰€æœ‰å›¾ç‰‡ä¸­çš„å¹³å‡å‡ºç°æ¬¡æ•°ï¼‰
        total_gt_pair_occurrences = sum(gt_pair_occurrences.values())  # GT pairåœ¨top-kä¸­çš„æ€»å‡ºç°æ¬¡æ•°ï¼ˆè·¨æ‰€æœ‰å›¾ç‰‡ï¼‰
        total_non_gt_pair_occurrences = sum(non_gt_pair_occurrences.values())  # éGT pairåœ¨top-kä¸­çš„æ€»å‡ºç°æ¬¡æ•°ï¼ˆè·¨æ‰€æœ‰å›¾ç‰‡ï¼‰
        unique_gt_pairs_in_topk = len(gt_pair_occurrences)  # top-kä¸­å”¯ä¸€çš„GT pairæ•°é‡ï¼ˆè·¨æ‰€æœ‰å›¾ç‰‡ï¼‰
        unique_non_gt_pairs_in_topk = len(non_gt_pair_occurrences)  # top-kä¸­å”¯ä¸€çš„éGT pairæ•°é‡ï¼ˆè·¨æ‰€æœ‰å›¾ç‰‡ï¼‰
        
        avg_gt_pair_occurrences_global = total_gt_pair_occurrences / unique_gt_pairs_in_topk if unique_gt_pairs_in_topk > 0 else 0.0
        avg_non_gt_pair_occurrences_global = total_non_gt_pair_occurrences / unique_non_gt_pairs_in_topk if unique_non_gt_pairs_in_topk > 0 else 0.0
        
        # æ–¹å¼2ï¼šæ¯å¼ å›¾ç‰‡å†…çš„å¹³å‡ï¼ˆåœ¨æ¯å¼ å›¾ç‰‡çš„top-kä¸­ï¼Œæ¯ä¸ªpairå¹³å‡å‡ºç°å¤šå°‘æ¬¡ï¼‰
        avg_gt_pair_occurrences_per_image = np.mean(gt_pair_occurrences_per_image) if gt_pair_occurrences_per_image else 0.0
        avg_non_gt_pair_occurrences_per_image = np.mean(non_gt_pair_occurrences_per_image) if non_gt_pair_occurrences_per_image else 0.0
        
        # æ•´ä½“æŒ‡æ ‡ï¼ˆè·¨æ‰€æœ‰å›¾ç‰‡ç´¯è®¡ï¼‰
        # å¬å›ç‡ (Recall/Sensitivity): TP / (TP + FN)
        recall_overall = tp / total_gt_pairs if total_gt_pairs > 0 else 0.0
        
        # ç²¾ç¡®ç‡ (Precision): TP / (TP + FP)
        precision_overall = tp / total_top_k_pairs if total_top_k_pairs > 0 else 0.0
        
        # F1åˆ†æ•°
        f1_overall = 2 * precision_overall * recall_overall / (precision_overall + recall_overall) if (precision_overall + recall_overall) > 0 else 0.0
        
        # å‡†ç¡®ç‡ (Accuracy): (TP + TN) / (TP + TN + FP + FN)
        accuracy_overall = (tp + tn) / (tp + tn + fp + fn) if (tp + tn + fp + fn) > 0 else 0.0
        
        # ç‰¹å¼‚æ€§ (Specificity): TN / (TN + FP)
        specificity_overall = tn / (tn + fp) if (tn + fp) > 0 else 0.0
        
        # å¹³å‡æŒ‡æ ‡ï¼ˆæ¯å¼ å›¾ç‰‡çš„å¹³å‡å€¼ï¼‰
        recall_avg = np.mean(image_recalls) if image_recalls else 0.0
        precision_avg = np.mean(image_precisions) if image_precisions else 0.0
        f1_avg = np.mean(image_f1s) if image_f1s else 0.0
        accuracy_avg = np.mean(image_accuracies) if image_accuracies else 0.0
        specificity_avg = np.mean(image_specificities) if image_specificities else 0.0
        
        results[f'confusion_matrix@{k}'] = {
            'matrix': cm.tolist(),
            'tp': int(tp),
            'fp': int(fp),
            'fn': int(fn),
            'tn': int(tn),
            'tn_true': int(tn_true),  # çœŸæ­£çš„TN: ä¸åœ¨GTä¸­ä¸”ä¸åœ¨top-kä¸­çš„pair
            'total_gt_pairs': int(total_gt_pairs),
            'total_top_k_pairs': int(total_top_k_pairs),
            'total_top_k_non_gt_pairs': int(total_top_k_non_gt_pairs),
            'total_top_k_pairs_all': int(total_top_k_pairs_all),
            'avg_gt_pair_occurrences_per_image': avg_gt_pair_occurrences_per_image,  # GT pairåœ¨æ¯å¼ å›¾ç‰‡top-kä¸­çš„å¹³å‡å‡ºç°æ¬¡æ•°
            'avg_non_gt_pair_occurrences_per_image': avg_non_gt_pair_occurrences_per_image,  # éGT pairåœ¨æ¯å¼ å›¾ç‰‡top-kä¸­çš„å¹³å‡å‡ºç°æ¬¡æ•°
            'avg_gt_pair_occurrences_global': avg_gt_pair_occurrences_global,  # GT pairè·¨æ‰€æœ‰å›¾ç‰‡çš„å¹³å‡å‡ºç°æ¬¡æ•°
            'avg_non_gt_pair_occurrences_global': avg_non_gt_pair_occurrences_global,  # éGT pairè·¨æ‰€æœ‰å›¾ç‰‡çš„å¹³å‡å‡ºç°æ¬¡æ•°
            'total_gt_pair_occurrences': int(total_gt_pair_occurrences),  # GT pairåœ¨top-kä¸­çš„æ€»å‡ºç°æ¬¡æ•°
            'total_non_gt_pair_occurrences': int(total_non_gt_pair_occurrences),  # éGT pairåœ¨top-kä¸­çš„æ€»å‡ºç°æ¬¡æ•°
            'unique_gt_pairs_in_topk': int(unique_gt_pairs_in_topk),  # top-kä¸­å”¯ä¸€çš„GT pairæ•°é‡
            'unique_non_gt_pairs_in_topk': int(unique_non_gt_pairs_in_topk),  # top-kä¸­å”¯ä¸€çš„éGT pairæ•°é‡
            # æ•´ä½“æŒ‡æ ‡ï¼ˆè·¨æ‰€æœ‰å›¾ç‰‡ç´¯è®¡ï¼‰
            'recall_overall': recall_overall,
            'precision_overall': precision_overall,
            'f1_overall': f1_overall,
            'accuracy_overall': accuracy_overall,
            'specificity_overall': specificity_overall,
            # å¹³å‡æŒ‡æ ‡ï¼ˆæ¯å¼ å›¾ç‰‡çš„å¹³å‡å€¼ï¼‰
            'recall_avg': recall_avg,
            'precision_avg': precision_avg,
            'f1_avg': f1_avg,
            'accuracy_avg': accuracy_avg,
            'specificity_avg': specificity_avg,
            # å‘åå…¼å®¹ï¼ˆä½¿ç”¨æ•´ä½“æŒ‡æ ‡ï¼‰
            'recall': recall_overall,
            'precision': precision_overall,
            'f1': f1_overall,
            'accuracy': accuracy_overall,
            'specificity': specificity_overall
        }
        
        print(f"   æ··æ·†çŸ©é˜µ (2x2):")
        print(f"               é¢„æµ‹ä¸ºæ­£ä¾‹(åœ¨top-k)  é¢„æµ‹ä¸ºè´Ÿä¾‹(ä¸åœ¨top-k)")
        print(f"   å®é™…ä¸ºæ­£ä¾‹(åœ¨GT)    TP={tp:6d}        FN={fn:6d}")
        print(f"   å®é™…ä¸ºè´Ÿä¾‹(ä¸åœ¨GT)  FP={fp:6d}        TN={tn:6d}")
        print(f"   æŒ‡æ ‡ (æ¯å¼ å›¾ç‰‡å¹³å‡):")
        print(f"     å¬å›ç‡ (Recall): {recall_avg:.4f} ({recall_avg*100:.2f}%)")
        print(f"     ç²¾ç¡®ç‡ (Precision): {precision_avg:.4f} ({precision_avg*100:.2f}%)")
        print(f"     ç‰¹å¼‚æ€§ (Specificity): {specificity_avg:.4f} ({specificity_avg*100:.2f}%)")
        print(f"     F1åˆ†æ•°: {f1_avg:.4f}")
        print(f"     å‡†ç¡®ç‡ (Accuracy): {accuracy_avg:.4f} ({accuracy_avg*100:.2f}%)")
        print(f"   æŒ‡æ ‡ (æ•´ä½“ç´¯è®¡):")
        print(f"     å¬å›ç‡ (Recall): {recall_overall:.4f} ({recall_overall*100:.2f}%)")
        print(f"     ç²¾ç¡®ç‡ (Precision): {precision_overall:.4f} ({precision_overall*100:.2f}%)")
        print(f"     ç‰¹å¼‚æ€§ (Specificity): {specificity_overall:.4f} ({specificity_overall*100:.2f}%)")
        print(f"     F1åˆ†æ•°: {f1_overall:.4f}")
        print(f"     å‡†ç¡®ç‡ (Accuracy): {accuracy_overall:.4f} ({accuracy_overall*100:.2f}%)")
        print(f"   ç»Ÿè®¡: GTä¸­æœ‰{total_gt_pairs}ä¸ªpair, top-kä¸­æœ‰{total_top_k_pairs_all}ä¸ªpair (å…¶ä¸­{total_top_k_pairs}ä¸ªGT pair, {total_top_k_non_gt_pairs}ä¸ªéGT pair)")
        print(f"   çœŸæ­£çš„TN (ä¸åœ¨GTä¸­ä¸”ä¸åœ¨top-kä¸­): {tn_true}")
        print(f"   Pairå‡ºç°æ¬¡æ•°ç»Ÿè®¡ (æ¯å¼ å›¾ç‰‡å†…):")
        print(f"     GT pairå¹³å‡å‡ºç°æ¬¡æ•°: {avg_gt_pair_occurrences_per_image:.4f} (åœ¨æ¯å¼ å›¾ç‰‡çš„top-{k}ä¸­)")
        print(f"     éGT pairå¹³å‡å‡ºç°æ¬¡æ•°: {avg_non_gt_pair_occurrences_per_image:.4f} (åœ¨æ¯å¼ å›¾ç‰‡çš„top-{k}ä¸­)")
        print(f"   Pairå‡ºç°æ¬¡æ•°ç»Ÿè®¡ (è·¨æ‰€æœ‰å›¾ç‰‡):")
        print(f"     GT pairå¹³å‡å‡ºç°æ¬¡æ•°: {avg_gt_pair_occurrences_global:.4f} (æ€»å‡ºç°{total_gt_pair_occurrences}æ¬¡, å”¯ä¸€{unique_gt_pairs_in_topk}ä¸ªpair)")
        print(f"     éGT pairå¹³å‡å‡ºç°æ¬¡æ•°: {avg_non_gt_pair_occurrences_global:.4f} (æ€»å‡ºç°{total_non_gt_pair_occurrences}æ¬¡, å”¯ä¸€{unique_non_gt_pairs_in_topk}ä¸ªpair)")
    
    print()
    return results


def display_confusion_matrix(cm_data: Dict, k: int, output_path: str = None):
    """
    æ˜¾ç¤º2x2æ··æ·†çŸ©é˜µï¼ˆpairå¬å›ï¼‰
    
    Args:
        cm_data: æ··æ·†çŸ©é˜µæ•°æ®
        k: Kå€¼
        output_path: ä¿å­˜å›¾ç‰‡çš„è·¯å¾„ï¼ˆå¯é€‰ï¼‰
    """
    if not HAS_PLOTTING:
        print(f"   âš ï¸  æœªå®‰è£…matplotlib/seabornï¼Œæ— æ³•æ˜¾ç¤ºæ··æ·†çŸ©é˜µå›¾ç‰‡")
        return
    
    key = f'confusion_matrix@{k}'
    if key not in cm_data:
        return
    
    cm = np.array(cm_data[key]['matrix'])
    
    # å½’ä¸€åŒ–æ··æ·†çŸ©é˜µï¼ˆæŒ‰è¡Œå½’ä¸€åŒ–ï¼Œæ˜¾ç¤ºå¬å›ç‡ï¼‰
    cm_normalized = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-8)
    
    # åˆ›å»ºå›¾å½¢
    plt.figure(figsize=(8, 6))
    
    sns.heatmap(cm_normalized, 
                annot=cm,  # æ˜¾ç¤ºåŸå§‹æ•°å€¼
                fmt='d',
                cmap='Blues',
                xticklabels=['é¢„æµ‹ä¸ºæ­£ä¾‹(åœ¨top-k)', 'é¢„æµ‹ä¸ºè´Ÿä¾‹(ä¸åœ¨top-k)'],
                yticklabels=['å®é™…ä¸ºæ­£ä¾‹(åœ¨GT)', 'å®é™…ä¸ºè´Ÿä¾‹(ä¸åœ¨GT)'],
                cbar_kws={'label': 'å½’ä¸€åŒ–å€¼'})
    plt.title(f'Pairå¬å›æ··æ·†çŸ©é˜µ (Top-{k})', fontsize=14, fontweight='bold')
    plt.xlabel('é¢„æµ‹', fontsize=12)
    plt.ylabel('å®é™…', fontsize=12)
    plt.tight_layout()
    
    if output_path:
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"   æ··æ·†çŸ©é˜µå·²ä¿å­˜åˆ°: {output_path}")
    else:
        plt.show()
    
    plt.close()


def print_candidate_pair_statistics(candidate_stats: Dict) -> None:
    """æ‰“å°å€™é€‰pairç»Ÿè®¡ä¿¡æ¯"""
    if candidate_stats is None:
        print("âš ï¸  æ— æ³•ç»Ÿè®¡å€™é€‰pairä¿¡æ¯")
        return
    
    print(f"\n{'='*80}")
    print("æ‰€æœ‰å€™é€‰ä¸­çš„Pairç»Ÿè®¡ï¼ˆåªçœ‹subject-objectå¯¹ï¼Œä¸è€ƒè™‘predicateï¼‰")
    print(f"{'='*80}")
    print(f"æ€»å€™é€‰pairæ•°ï¼ˆå…¨å±€å»é‡ï¼‰: {candidate_stats['total_candidate_pairs']:,}")
    if 'total_candidate_pairs_sum' in candidate_stats:
        print(f"æ€»å€™é€‰pairæ•°ï¼ˆæ‰€æœ‰å›¾ç‰‡æ€»å’Œï¼Œæœªå»é‡ï¼‰: {candidate_stats['total_candidate_pairs_sum']:,}")
        if candidate_stats['total_candidate_pairs_sum'] > 0:
            dedup_ratio = candidate_stats['total_candidate_pairs'] / candidate_stats['total_candidate_pairs_sum']
            print(f"  å»é‡æ¯”ä¾‹: {dedup_ratio:.2%} (è¯´æ˜æœ‰ {candidate_stats['total_candidate_pairs_sum'] - candidate_stats['total_candidate_pairs']:,} ä¸ªpairåœ¨å¤šå¼ å›¾ç‰‡ä¸­é‡å¤å‡ºç°)")
    print(f"æœ‰GTçš„pairæ•°: {candidate_stats['pairs_with_gt']:,} ({candidate_stats['ratio_with_gt']:.2%})")
    print(f"æ²¡æœ‰GTçš„pairæ•°: {candidate_stats['pairs_without_gt']:,} ({candidate_stats['ratio_without_gt']:.2%})")
    print(f"{'='*80}\n")


def print_summary(recall_results: Dict, cm_results: Dict = None) -> None:
    """æ‰“å°æ€»ç»“ä¿¡æ¯"""
    # æ˜¾ç¤ºæ‰€æœ‰Kå€¼çš„å¬å›ç‡
    k_values = sorted([int(k.split('@')[1]) for k in recall_results.keys() if k.startswith('recall@')])
    for k in k_values:
        key = f'recall@{k}'
        if key in recall_results:
            result = recall_results[key]
            print(f"Recall@{k}: {result['overall_recall']:.4f} ({result['overall_recall']*100:.2f}%) - {result['total_recalled_pairs']}/{result['total_gt_pairs']} pairs")


def print_recall_distribution_by_image_stats(recall_results: Dict, k: int = None) -> None:
    """
    æ‰“å°æŒ‰å®ä½“æ•°é‡å’Œå…³ç³»æ•°é‡åˆ†ç»„çš„å¬å›ç‡åˆ†å¸ƒè¡¨
    
    Args:
        recall_results: å¬å›ç‡ç»“æœå­—å…¸
        k: æŒ‡å®šçš„Kå€¼ï¼Œå¦‚æœä¸ºNoneåˆ™æ˜¾ç¤ºæ‰€æœ‰Kå€¼
    """
    k_values = sorted([int(k.split('@')[1]) for k in recall_results.keys() if k.startswith('recall@')])
    
    if k is not None:
        k_values = [k] if k in k_values else []
    
    for k_val in k_values:
        key = f'recall@{k_val}'
        if key not in recall_results:
            continue
        
        result = recall_results[key]
        image_recall_details = result.get('image_recall_details', [])
        
        if not image_recall_details:
            print(f"\nâš ï¸  Top-{k_val}: æ²¡æœ‰å›¾ç‰‡è¯¦ç»†ä¿¡æ¯ï¼Œæ— æ³•ç”Ÿæˆåˆ†å¸ƒè¡¨")
            continue
        
        # æŒ‰å®ä½“æ•°é‡å’Œå…³ç³»æ•°é‡åˆ†ç»„
        # å®šä¹‰åˆ†ç»„åŒºé—´
        object_bins = [
            (0, 5, "1-5"),
            (6, 10, "6-10"),
            (11, 15, "11-15"),
            (16, 20, "16-20"),
            (21, 30, "21-30"),
            (31, 50, "31-50"),
            (51, 100, "51-100"),
            (101, float('inf'), "101+")
        ]
        
        relation_bins = [
            (0, 5, "1-5"),
            (6, 10, "6-10"),
            (11, 15, "11-15"),
            (16, 20, "16-20"),
            (21, 30, "21-30"),
            (31, 50, "31-50"),
            (51, 100, "51-100"),
            (101, float('inf'), "101+")
        ]
        
        def get_bin_label(value, bins):
            """æ ¹æ®å€¼è¿”å›å¯¹åº”çš„åˆ†ç»„æ ‡ç­¾"""
            # å¤„ç†0å€¼çš„æƒ…å†µ
            if value == 0:
                return "0"
            for min_val, max_val, label in bins:
                if min_val <= value <= max_val:
                    return label
            return "æœªçŸ¥"
        
        # ç»Ÿè®¡æ¯ä¸ªåˆ†ç»„çš„å¬å›ç‡
        group_stats = defaultdict(lambda: {
            'recalls': [],
            'total_recalled_pairs': 0,
            'total_gt_pairs': 0,
            'num_images': 0
        })
        
        for detail in image_recall_details:
            num_objects = detail['num_objects']
            num_relations = detail['num_relations']
            recall = detail['recall']
            recalled_pairs = detail['recalled_pairs']
            total_gt_pairs = detail['total_gt_pairs']
            
            obj_bin = get_bin_label(num_objects, object_bins)
            rel_bin = get_bin_label(num_relations, relation_bins)
            
            group_key = (obj_bin, rel_bin)
            group_stats[group_key]['recalls'].append(recall)
            group_stats[group_key]['total_recalled_pairs'] += recalled_pairs
            group_stats[group_key]['total_gt_pairs'] += total_gt_pairs
            group_stats[group_key]['num_images'] += 1
        
        # æ‰“å°åˆ†å¸ƒè¡¨
        print(f"\n{'='*80}")
        print(f"Top-{k_val}: æŒ‰å®ä½“æ•°é‡å’Œå…³ç³»æ•°é‡åˆ†ç»„çš„GT Pairå¬å›ç‡åˆ†å¸ƒè¡¨")
        print(f"{'='*80}")
        
        def sort_bin_key(x):
            """ç”¨äºæ’åºåˆ†ç»„æ ‡ç­¾çš„å‡½æ•°"""
            if x == "0":
                return 0
            if '-' in x:
                return int(x.split('-')[0])
            if '+' in x:
                return int(x.replace('+', ''))
            if x == "æœªçŸ¥":
                return 9999
            return 999
        
        # è·å–æ‰€æœ‰å”¯ä¸€çš„å…³ç³»æ•°é‡åˆ†ç»„å’Œå®ä½“æ•°é‡åˆ†ç»„
        unique_obj_bins = sorted(set([obj_bin for obj_bin, _ in group_stats.keys()]), key=sort_bin_key)
        unique_rel_bins = sorted(set([rel_bin for _, rel_bin in group_stats.keys()]), key=sort_bin_key)
        
        # æ‰“å°è¡¨å¤´
        header = f"{'å…³ç³»æ•°é‡':<12}"
        for obj_bin in unique_obj_bins:
            header += f" | {obj_bin:>12}"
        header += f" | {'å¹³å‡':>12}"
        print(header)
        print("-" * len(header))
        
        # æ‰“å°æ¯ä¸€è¡Œï¼ˆæŒ‰å…³ç³»æ•°é‡åˆ†ç»„ï¼‰
        for rel_bin in unique_rel_bins:
            row = f"{rel_bin:<12}"
            row_recalls = []
            for obj_bin in unique_obj_bins:
                group_key = (obj_bin, rel_bin)
                if group_key in group_stats:
                    stats = group_stats[group_key]
                    avg_recall = np.mean(stats['recalls']) if stats['recalls'] else 0.0
                    overall_recall = stats['total_recalled_pairs'] / stats['total_gt_pairs'] if stats['total_gt_pairs'] > 0 else 0.0
                    # ä½¿ç”¨æ•´ä½“å¬å›ç‡ï¼ˆæ›´å‡†ç¡®ï¼‰
                    recall_to_show = overall_recall
                    row_recalls.append(recall_to_show)
                    row += f" | {recall_to_show:>11.2%}"
                else:
                    row += f" | {'-':>12}"
            
            # è®¡ç®—è¯¥è¡Œçš„å¹³å‡å¬å›ç‡
            if row_recalls:
                row_avg = np.mean(row_recalls)
                row += f" | {row_avg:>11.2%}"
            else:
                row += f" | {'-':>12}"
            print(row)
        
        # æ‰“å°åˆ—å¹³å‡
        print("-" * len(header))
        col_avg_row = f"{'å¹³å‡':<12}"
        for obj_bin in unique_obj_bins:
            col_recalls = []
            for rel_bin in unique_rel_bins:
                group_key = (obj_bin, rel_bin)
                if group_key in group_stats:
                    stats = group_stats[group_key]
                    overall_recall = stats['total_recalled_pairs'] / stats['total_gt_pairs'] if stats['total_gt_pairs'] > 0 else 0.0
                    col_recalls.append(overall_recall)
            if col_recalls:
                col_avg = np.mean(col_recalls)
                col_avg_row += f" | {col_avg:>11.2%}"
            else:
                col_avg_row += f" | {'-':>12}"
        
        # æ€»ä½“å¹³å‡
        all_recalls = []
        for stats in group_stats.values():
            if stats['total_gt_pairs'] > 0:
                overall_recall = stats['total_recalled_pairs'] / stats['total_gt_pairs']
                all_recalls.append(overall_recall)
        if all_recalls:
            overall_avg = np.mean(all_recalls)
            col_avg_row += f" | {overall_avg:>11.2%}"
        else:
            col_avg_row += f" | {'-':>12}"
        print(col_avg_row)
        
        # æ‰“å°æ¯ä¸ªåˆ†ç»„çš„è¯¦ç»†ä¿¡æ¯ï¼ˆå›¾ç‰‡æ•°é‡ã€GT pairæ•°é‡ç­‰ï¼‰
        print(f"\nè¯¦ç»†ç»Ÿè®¡ä¿¡æ¯:")
        print(f"{'å®ä½“æ•°é‡':<12} | {'å…³ç³»æ•°é‡':<12} | {'å›¾ç‰‡æ•°':>8} | {'GT Pairs':>12} | {'å¬å›Pairs':>12} | {'å¬å›ç‡':>10}")
        print("-" * 80)
        def sort_group_key(x):
            """ç”¨äºæ’åºåˆ†ç»„é”®çš„å‡½æ•°"""
            obj_bin, rel_bin = x[0]
            obj_key = sort_bin_key(obj_bin)
            rel_key = sort_bin_key(rel_bin)
            return (obj_key, rel_key)
        
        for (obj_bin, rel_bin), stats in sorted(group_stats.items(), key=sort_group_key):
            overall_recall = stats['total_recalled_pairs'] / stats['total_gt_pairs'] if stats['total_gt_pairs'] > 0 else 0.0
            print(f"{obj_bin:<12} | {rel_bin:<12} | {stats['num_images']:>8} | {stats['total_gt_pairs']:>12} | {stats['total_recalled_pairs']:>12} | {overall_recall:>9.2%}")
        
        print(f"{'='*80}\n")


def export_results(recall_results: Dict, cm_results: Dict = None, output_path: str = None) -> None:
    """å¯¼å‡ºç»“æœåˆ°JSONæ–‡ä»¶"""
    print(f"ğŸ’¾ æ­£åœ¨å¯¼å‡ºç»“æœåˆ°: {output_path}")
    
    export_data = {
        'recall_results': recall_results,
        'confusion_matrix_results': cm_results
    }
    
    # å°†numpyæ•°ç»„è½¬æ¢ä¸ºåˆ—è¡¨
    if cm_results:
        for k in [50, 100]:
            key = f'confusion_matrix@{k}'
            if key in cm_results:
                # matrixå·²ç»æ˜¯listäº†ï¼Œä¸éœ€è¦è½¬æ¢
                pass
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(export_data, f, indent=2, ensure_ascii=False)
    
    print(f"âœ… ç»“æœå·²å¯¼å‡º\n")


def main():
    parser = argparse.ArgumentParser(
        description="è¯„ä¼°åœºæ™¯å›¾å…³ç³»é¢„æµ‹ç»“æœ - Top-Kå¬å›ç‡å’Œæ··æ·†çŸ©é˜µ",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:
  # åŸºæœ¬è¯„ä¼°ï¼ˆé»˜è®¤è®¡ç®—top50å’Œtop100ï¼‰
  python topk_relation_filter.py --json_file results.json
  
  # è‡ªå®šä¹‰Kå€¼
  python topk_relation_filter.py --json_file results.json --k-values 50 100 200
  
  # ä¿å­˜æ··æ·†çŸ©é˜µå›¾ç‰‡
  python topk_relation_filter.py --json_file results.json --save-cm-fig
  
  # å¯¼å‡ºç»“æœ
  python topk_relation_filter.py --json_file results.json --export results.json
        """
    )
    
    parser.add_argument('--json_file', type=str, 
                       default='/public/home/xiaojw2025/Data/embedding_similarity/vlm2vec_qwen2vl/result_recall_2000.json',
                       help='é¢„æµ‹ç»“æœJSONæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--gt_file', type=str, default='/public/home/xiaojw2025/Workspace/RAHP/DATASET/VG150/test_2000_images.json',
                       help='GTæ–‡ä»¶è·¯å¾„ï¼ˆå¦‚æœæä¾›ï¼Œå°†ä½¿ç”¨å®Œæ•´GTæ•°æ®ä½œä¸ºåˆ†æ¯ï¼‰')
    parser.add_argument('--k-values', type=int, nargs='+', default=[50, 100,20000],
                       help='æŒ‡å®šè¦è®¡ç®—çš„Kå€¼åˆ—è¡¨ï¼ˆé»˜è®¤: 50 100ï¼‰')
    parser.add_argument('--export', type=str, default=None,
                       help='å¯¼å‡ºç»“æœåˆ°æŒ‡å®šJSONæ–‡ä»¶')
    parser.add_argument('--save-cm-fig', action='store_true',
                       help='ä¿å­˜æ··æ·†çŸ©é˜µå›¾ç‰‡')
    parser.add_argument('--cm-fig-dir', type=str, default='./',
                       help='æ··æ·†çŸ©é˜µå›¾ç‰‡ä¿å­˜ç›®å½•ï¼ˆé»˜è®¤: ./ï¼‰')
    
    args = parser.parse_args()
    
    # åŠ è½½GTæ•°æ®ï¼ˆå¦‚æœæä¾›ï¼‰
    gt_pairs_per_image = None
    image_stats = None
    if args.gt_file:
        gt_pairs_per_image, image_stats = load_gt_data(args.gt_file)
    
    # åŠ è½½ç»“æœ
    data = load_results(args.json_file)
    
    # ç»Ÿè®¡æ‰€æœ‰å€™é€‰ä¸­çš„pairæƒ…å†µï¼ˆæœ‰GT vs æ²¡æœ‰GTï¼‰
    candidate_stats = calculate_candidate_pair_statistics(data, gt_pairs_per_image)
    print_candidate_pair_statistics(candidate_stats)
    
    # è®¡ç®—å¬å›ç‡
    recall_results = calculate_recall_at_k(data, gt_pairs_per_image, image_stats, args.k_values)
    
    # æ‰“å°æ€»ç»“ï¼ˆåªæ˜¾ç¤ºå¬å›ç‡ï¼‰
    print_summary(recall_results)
    
    # æ‰“å°æŒ‰å®ä½“æ•°é‡å’Œå…³ç³»æ•°é‡åˆ†ç»„çš„å¬å›ç‡åˆ†å¸ƒè¡¨
    print_recall_distribution_by_image_stats(recall_results)
    
    # å¯é€‰ï¼šè®¡ç®—æ··æ·†çŸ©é˜µï¼ˆå¦‚æœéœ€è¦ï¼‰
    cm_results = None
    if args.save_cm_fig:
        cm_results = calculate_confusion_matrix(data, gt_pairs_per_image, args.k_values)
        import os
        os.makedirs(args.cm_fig_dir, exist_ok=True)
        for k in args.k_values:
            fig_path = os.path.join(args.cm_fig_dir, f'confusion_matrix_top{k}.png')
            display_confusion_matrix(cm_results, k, output_path=fig_path)
    
    # å¯¼å‡ºç»“æœ
    if args.export:
        export_results(recall_results, cm_results, args.export)
    
    print("âœ… è¯„ä¼°å®Œæˆ")


if __name__ == "__main__":
    main()


import json
import torch
from PIL import Image
from tqdm import tqdm
import os
import sys
import warnings


def check_flash_attention_support():

    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
        if not torch.cuda.is_available():
            return False, "CUDAä¸å¯ç”¨"
        
        # è·å–GPUè®¡ç®—èƒ½åŠ›
        device_capability = torch.cuda.get_device_capability()
        major, minor = device_capability
        compute_capability = major * 10 + minor
        
        # Flash Attention 2éœ€è¦è®¡ç®—èƒ½åŠ› >= 8.0 (AmpereåŠä»¥ä¸Šæ¶æ„)
        # Flash Attention 1éœ€è¦è®¡ç®—èƒ½åŠ› >= 7.5 (TuringåŠä»¥ä¸Šæ¶æ„)
        if compute_capability >= 80:
            # å°è¯•å¯¼å…¥flash_attn
            try:
                import flash_attn
                return True, f"æ”¯æŒFlash Attention (GPUè®¡ç®—èƒ½åŠ›: {major}.{minor})"
            except ImportError:
                return False, f"GPUæ”¯æŒä½†æœªå®‰è£…flash_attnåŒ… (è®¡ç®—èƒ½åŠ›: {major}.{minor})"
        else:
            return False, f"GPUè®¡ç®—èƒ½åŠ›ä¸è¶³ (å½“å‰: {major}.{minor}, éœ€è¦: >= 8.0)"
            
    except Exception as e:
        return False, f"æ£€æµ‹å¤±è´¥: {str(e)}"


def configure_attention_backend():

    is_supported, message = check_flash_attention_support()
    
    print("\n" + "="*80)
    print("æ³¨æ„åŠ›æœºåˆ¶é…ç½®")
    print("="*80)
    
    if is_supported:
        print(f"âœ… {message}")
        print("   ä½¿ç”¨: Flash Attention (æœ€å¿«)")
        os.environ["ATTN_IMPLEMENTATION"] = "flash_attention_2"
        # åŒæ—¶è®¾ç½®transformersä½¿ç”¨çš„ç¯å¢ƒå˜é‡
        os.environ["USE_FLASH_ATTENTION"] = "1"
        return "flash_attn"
    else:
        print(f"âš ï¸  {message}")
        
        # æ£€æŸ¥PyTorchç‰ˆæœ¬æ˜¯å¦æ”¯æŒSDPA
        pytorch_version = torch.__version__
        major, minor = map(int, pytorch_version.split('.')[:2])
        
        if major >= 2:  # PyTorch 2.0+æ”¯æŒSDPA
            print("   é™çº§ä½¿ç”¨: Scaled Dot Product Attention (SDPA)")
            print("   æ€§èƒ½: ä¸­ç­‰ï¼Œä½†æ¯”eageræ¨¡å¼å¿«")
            os.environ["ATTN_IMPLEMENTATION"] = "sdpa"
            os.environ["USE_FLASH_ATTENTION"] = "0"
            return "sdpa"
        else:
            print("   é™çº§ä½¿ç”¨: Eager Attention (æ ‡å‡†å®ç°)")
            print("   æ€§èƒ½: è¾ƒæ…¢ï¼Œä½†å…¼å®¹æ€§æœ€å¥½")
            os.environ["ATTN_IMPLEMENTATION"] = "eager"
            os.environ["USE_FLASH_ATTENTION"] = "0"
            return "eager"
    
    print("="*80 + "\n")


_attn_type = configure_attention_backend()

# ç°åœ¨æ‰å¯¼å…¥VLM2Vecæ¨¡å—
from src.model.model import MMEBModel
from src.arguments import ModelArguments, DataArguments
from src.model.processor import load_processor, QWEN2_VL, VLM_IMAGE_TOKENS


INPUT_FILE = "/public/home/xiaojw2025/Workspace/RAHP/DATASET/VG150/test_200_images_cot.json"
OUTPUT_FILE = "/public/home/xiaojw2025/Workspace/VLM2Vec/cot/predict/recall_results_200_cot.json"

# 50ä¸ªè°“è¯åˆ—è¡¨
PREDICATES = [
    "above", "across", "against", "along", "and", "at", "attached to", "behind",
    "belonging to", "between", "carrying", "covered in", "covering", "eating",
    "flying in", "for", "from", "growing on", "hanging from", "has", "holding",
    "in", "in front of", "laying on", "looking at", "lying on", "made of",
    "mounted on", "near", "of", "on", "on back of", "over", "painted on",
    "parked on", "part of", "playing", "riding", "says", "sitting on",
    "standing on", "to", "under", "using", "walking in", "walking on",
    "watching", "wearing", "wears", "with","no relation"
]


def format_bbox_as_special_token(bbox, normalize=True, original_width=1024, original_height=1024):
    """å°†è¾¹ç•Œæ¡†è½¬æ¢ä¸ºQwen2-VLçš„special tokenæ ¼å¼"""
    if isinstance(bbox, (list, tuple)) and len(bbox) == 4:
        x1, y1, x2, y2 = bbox
        
        if normalize:
            x1_norm = int((x1 / original_width) * 1000)
            y1_norm = int((y1 / original_height) * 1000)
            x2_norm = int((x2 / original_width) * 1000)
            y2_norm = int((y2 / original_height) * 1000)
            
            x1_norm = max(0, min(x1_norm, 999))
            y1_norm = max(0, min(y1_norm, 999))
            x2_norm = max(0, min(x2_norm, 999))
            y2_norm = max(0, min(y2_norm, 999))
            
            x1_norm, x2_norm = min(x1_norm, x2_norm), max(x1_norm, x2_norm)
            y1_norm, y2_norm = min(y1_norm, y2_norm), max(y1_norm, y2_norm)
            
            if x1_norm == x2_norm:
                x2_norm = min(x1_norm + 1, 999)
            if y1_norm == y2_norm:
                y2_norm = min(y1_norm + 1, 999)
            
            return f"<|box_start|>({x1_norm}, {y1_norm}), ({x2_norm}, {y2_norm})<|box_end|>"
    return ""

def format_object_with_ref(object_label):
    return f"<|object_ref_start|>{object_label}<|object_ref_end|>"


def precompute_predicate_vectors(model, processor, predicates):
    """
    é¢„è®¡ç®—æ‰€æœ‰è°“è¯çš„å‘é‡è¡¨ç¤ºï¼ˆåªéœ€è¦è®¡ç®—ä¸€æ¬¡ï¼‰
    
    Args:
        model: VLM2Vecæ¨¡å‹
        processor: æ–‡æœ¬å¤„ç†å™¨
        predicates: è°“è¯åˆ—è¡¨
    
    Returns:
        predicate_vectors: [num_predicates, hidden_dim] çš„tensor
    """
    print("ğŸ”§ é¢„è®¡ç®—è°“è¯å‘é‡...")
    predicate_vectors = []
    
    for predicate in tqdm(predicates, desc="ç¼–ç è°“è¯"):
        predicate_text = f"The subject is {predicate} the object."
        inputs = processor(text=predicate_text, images=None, return_tensors="pt")
        inputs = {key: value.to('cuda') for key, value in inputs.items()}
        
        with torch.no_grad():
            tgt_output = model(tgt=inputs)["tgt_reps"]
            predicate_vectors.append(tgt_output)
    
    # å †å æˆä¸€ä¸ªtensor: [num_predicates, hidden_dim]
    predicate_vectors = torch.cat(predicate_vectors, dim=0)
    print(f"âœ… è°“è¯å‘é‡é¢„è®¡ç®—å®Œæˆï¼Œshape: {predicate_vectors.shape}")
    
    return predicate_vectors


def predict_relation(model, processor, query_text, predicate_vectors=None):
    """
    é¢„æµ‹å…³ç³»ï¼Œä½¿ç”¨é¢„è®¡ç®—çš„è°“è¯å‘é‡
    
    Args:
        model: VLM2Vecæ¨¡å‹
        processor: æ–‡æœ¬å¤„ç†å™¨
        query_text: æŸ¥è¯¢æ–‡æœ¬ï¼ˆå·²ç»åŒ…å«å…³ç³»æè¿°çš„æ–‡æœ¬ï¼‰
        predicate_vectors: é¢„è®¡ç®—çš„è°“è¯å‘é‡ [num_predicates, hidden_dim]ï¼Œå¦‚æœä¸ºNoneåˆ™å®æ—¶è®¡ç®—
    
    Returns:
        predicate_scores: è°“è¯åŠå…¶ç›¸ä¼¼åº¦åˆ†æ•°çš„åˆ—è¡¨
    """
    # ä½¿ç”¨query_textä½œä¸ºqueryï¼ˆçº¯æ–‡æœ¬ï¼Œä¸éœ€è¦å›¾åƒï¼‰
    # query_textå·²ç»æ˜¯æè¿°ä¸¤ä¸ªç‰©ä½“å…³ç³»çš„æ–‡æœ¬äº†
    inputs = processor(text=query_text, images=None, return_tensors="pt")
    inputs = {key: value.to('cuda') for key, value in inputs.items()}
    
    try:
        with torch.no_grad():
            qry_output = model(tgt=inputs)["tgt_reps"]  # ä½¿ç”¨tgtå› ä¸ºè¿™æ˜¯çº¯æ–‡æœ¬è¾“å…¥
    except RuntimeError as e:
        # æ•è·Flash Attentionè¿è¡Œæ—¶é”™è¯¯
        if "FlashAttention only supports Ampere" in str(e):
            raise RuntimeError(
                "æ£€æµ‹åˆ°Flash Attentionè¿è¡Œæ—¶é”™è¯¯ï¼šæ‚¨çš„GPUä¸æ”¯æŒFlash Attentionã€‚\n"
                "è¯·åœ¨è¿è¡Œè„šæœ¬å‰è®¾ç½®ç¯å¢ƒå˜é‡: export USE_FLASH_ATTENTION=0\n"
                f"åŸå§‹é”™è¯¯: {str(e)}"
            )
        else:
            raise
    
    # è®¡ç®—ä¸æ‰€æœ‰è°“è¯çš„ç›¸ä¼¼åº¦
    predicate_scores = []
    
    if predicate_vectors is not None:
        # ä½¿ç”¨é¢„è®¡ç®—çš„è°“è¯å‘é‡ï¼ˆé€ä¸ªè®¡ç®—ç›¸ä¼¼åº¦ï¼‰
        with torch.no_grad():
            # qry_output: [1, hidden_dim]
            # predicate_vectors: [num_predicates, hidden_dim]
            for i, predicate in enumerate(PREDICATES):
                similarity = model.compute_similarity(
                    qry_output, 
                    predicate_vectors[i:i+1]  # å–å•ä¸ªè°“è¯å‘é‡ [1, hidden_dim]
                )
                predicate_scores.append({
                    'predicate': predicate,
                    'similarity': similarity.item()
                })
    else:
        # åŸå§‹æ–¹æ³•ï¼šé€ä¸ªç¼–ç è°“è¯ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        for predicate in PREDICATES:
            pred_inputs = processor(text=f"The subject is {predicate} the object.", images=None, return_tensors="pt")
            pred_inputs = {key: value.to('cuda') for key, value in pred_inputs.items()}
            
            with torch.no_grad():
                tgt_output = model(tgt=pred_inputs)["tgt_reps"]
                similarity = model.compute_similarity(qry_output, tgt_output)
            
            predicate_scores.append({
                'predicate': predicate,
                'similarity': similarity.item()
            })
    
    return predicate_scores


def calculate_recall_at_k_per_image(image_candidate_predictions, k=50):
    """
    è®¡ç®—å•å¼ å›¾ç‰‡çš„recall@k
    ç°åœ¨æ”¯æŒæ‰€æœ‰ç‰©ä½“ä¸¤ä¸¤é…å¯¹çš„é¢„æµ‹ç»“æœ
    """
    # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œå–top-kï¼ˆå¦‚æœå€™é€‰æ•°ä¸è¶³kï¼Œåˆ™å–å…¨éƒ¨ï¼‰
    predictions_sorted = sorted(image_candidate_predictions, key=lambda x: x['similarity'], reverse=True)
    actual_k = min(k, len(predictions_sorted))  # å¦‚æœå€™é€‰æ•°ä¸è¶³kï¼Œå–å…¨éƒ¨
    top_k_predictions = predictions_sorted[:actual_k]
    
    # ç»Ÿè®¡top-kä¸­é¢„æµ‹æ­£ç¡®çš„å…³ç³»ï¼ˆå»é‡ï¼Œæ¯ä¸ªå…³ç³»åªç®—ä¸€æ¬¡ï¼‰ï¼Œæ’é™¤no relationé¢„æµ‹
    recalled_relations = set()
    for pred in top_k_predictions:
        if pred['is_correct'] and pred['relation_idx'] != -1 and pred.get('predicted_predicate') != 'no relation':  # åªç»Ÿè®¡æœ‰GTçš„å…³ç³»ï¼Œæ’é™¤no relationé¢„æµ‹
            recalled_relations.add(pred['relation_idx'])
    
    # æ€»GTå…³ç³»æ•°ï¼ˆä»å€™é€‰ä¸­æå–æœ‰GTçš„å…³ç³»çš„å”¯ä¸€relation_idxæ•°é‡ï¼‰
    gt_relations = [pred for pred in image_candidate_predictions if pred['has_gt'] and pred['relation_idx'] != -1]
    total_gt_relations = len(set(pred['relation_idx'] for pred in gt_relations))
    
    recall = len(recalled_relations) / total_gt_relations if total_gt_relations > 0 else 0.0
    
    # ç»Ÿè®¡æ€»é¢„æµ‹å¯¹æ•°ï¼ˆåŒ…æ‹¬æ— GTçš„é…å¯¹ï¼‰
    total_pairs = len(set((pred['subject'], pred['object']) for pred in image_candidate_predictions))
    gt_pairs = len(set((pred['subject'], pred['object']) for pred in image_candidate_predictions if pred['has_gt']))
    
    return {
        'recall@k': recall,
        'k': k,
        'actual_k': actual_k,  # å®é™…å–çš„æ•°é‡
        'recalled_relations': len(recalled_relations),
        'total_gt_relations': total_gt_relations,
        'total_candidates': len(image_candidate_predictions),
        'top_k_candidates': len(top_k_predictions),
        'total_pairs': total_pairs,  # æ€»é¢„æµ‹å¯¹æ•°
        'gt_pairs': gt_pairs,  # æœ‰GTçš„é…å¯¹å¯¹æ•°
        'non_gt_pairs': total_pairs - gt_pairs  # æ— GTçš„é…å¯¹å¯¹æ•°
    }


def calculate_mean_recall_per_predicate(per_image_candidates, predicates, k=50):
    """
    è®¡ç®—æ¯ä¸ªè°“è¯ç±»åˆ«çš„mean recall@50
    
    Args:
        per_image_candidates: dict, keyä¸ºimage_id, valueä¸ºè¯¥å›¾ç‰‡çš„æ‰€æœ‰å€™é€‰é¢„æµ‹åˆ—è¡¨
        predicates: æ‰€æœ‰è°“è¯ç±»åˆ«åˆ—è¡¨
        k: top-k
    
    Returns:
        dict: æ¯ä¸ªè°“è¯çš„recallå’Œæ•´ä½“mean recall
    """
    # åˆå§‹åŒ–æ¯ä¸ªè°“è¯çš„ç»Ÿè®¡
    predicate_stats = {pred: {'hit': 0, 'total': 0} for pred in predicates}
    
    for image_id, candidates in per_image_candidates.items():
        # æŒ‰ç›¸ä¼¼åº¦æ’åºï¼Œå–top-kï¼ˆå¦‚æœå€™é€‰æ•°ä¸è¶³kï¼Œåˆ™å–å…¨éƒ¨ï¼‰
        predictions_sorted = sorted(candidates, key=lambda x: x['similarity'], reverse=True)
        actual_k = min(k, len(predictions_sorted))
        top_k_predictions = predictions_sorted[:actual_k]
        
        # ç»Ÿè®¡æ¯ä¸ªè°“è¯ç±»åˆ«çš„GTæ•°é‡å’Œå¬å›æ•°é‡
        # å…ˆç»Ÿè®¡è¯¥å›¾ç‰‡ä¸­æ¯ä¸ªè°“è¯ç±»åˆ«çš„GT
        gt_predicates_in_image = {}
        recalled_predicates_in_image = {}
        
        for cand in candidates:
            if not cand['has_gt'] or cand['relation_idx'] == -1:
                continue  # è·³è¿‡æ²¡æœ‰GTçš„é…å¯¹
                
            gt_pred = cand['gt_predicate']
            relation_idx = cand['relation_idx']
            
            # ç»Ÿè®¡GTï¼ˆæ¯ä¸ªå…³ç³»åªç®—ä¸€æ¬¡ï¼‰
            if relation_idx not in gt_predicates_in_image:
                gt_predicates_in_image[relation_idx] = gt_pred
                predicate_stats[gt_pred]['total'] += 1
        
        # ç»Ÿè®¡Top-Kä¸­å¬å›çš„è°“è¯ï¼ˆæ¯ä¸ªå…³ç³»åªç®—ä¸€æ¬¡ï¼‰ï¼Œæ’é™¤no relationé¢„æµ‹
        for cand in top_k_predictions:
            if cand['is_correct'] and cand.get('predicted_predicate') != 'no relation':
                relation_idx = cand['relation_idx']
                gt_pred = cand['gt_predicate']
                
                # æ¯ä¸ªå…³ç³»åªç®—ä¸€æ¬¡å¬å›
                if relation_idx not in recalled_predicates_in_image:
                    recalled_predicates_in_image[relation_idx] = gt_pred
                    predicate_stats[gt_pred]['hit'] += 1
    
    # è®¡ç®—æ¯ä¸ªè°“è¯çš„recall
    per_predicate_recall = {}
    valid_predicates = []
    
    for pred in predicates:
        total = predicate_stats[pred]['total']
        hit = predicate_stats[pred]['hit']
        
        if total > 0:
            recall = hit / total
            per_predicate_recall[pred] = {
                'recall': recall,
                'hit': hit,
                'total': total
            }
            valid_predicates.append(recall)
        else:
            per_predicate_recall[pred] = {
                'recall': 0.0,
                'hit': 0,
                'total': 0
            }
    
    # è®¡ç®—mean recallï¼ˆåªå¯¹æœ‰GTçš„ç±»åˆ«è®¡ç®—ï¼‰
    mean_recall = sum(valid_predicates) / len(valid_predicates) if valid_predicates else 0.0
    
    return {
        'mean_recall@k': mean_recall,
        'k': k,
        'per_predicate_recall': per_predicate_recall,
        'num_valid_predicates': len(valid_predicates),
        'total_predicates': len(predicates)
    }


def calculate_average_recall_at_k(per_image_candidates, k=50):

    per_image_results = []
    total_recall = 0.0
    valid_images = 0
    
    for image_id, candidates in per_image_candidates.items():
        # è®¡ç®—è¯¥å›¾ç‰‡çš„recall
        img_result = calculate_recall_at_k_per_image(candidates, k)
        img_result['image_id'] = image_id
        per_image_results.append(img_result)
        
        total_recall += img_result['recall@k']
        valid_images += 1
    
    # è®¡ç®—å¹³å‡recall
    avg_recall = total_recall / valid_images if valid_images > 0 else 0.0
    
    # ç»Ÿè®¡æ€»ä½“ä¿¡æ¯
    total_gt_relations = sum(r['total_gt_relations'] for r in per_image_results)
    total_recalled_relations = sum(r['recalled_relations'] for r in per_image_results)
    
    # ç»Ÿè®¡å€™é€‰æ•°ä¸è¶³kçš„å›¾ç‰‡æ•°é‡
    images_with_insufficient_candidates = sum(1 for r in per_image_results if r['actual_k'] < k)
    
    return {
        'avg_recall@k': avg_recall,
        'k': k,
        'total_images': valid_images,
        'total_gt_relations': total_gt_relations,
        'total_recalled_relations': total_recalled_relations,
        'images_with_insufficient_candidates': images_with_insufficient_candidates,
        'per_image_results': per_image_results
    }



def main():
    print("="*80)
    print("åœºæ™¯å›¾å…³ç³»é¢„æµ‹ä¸Per-Image Recall@50è®¡ç®—")
    print("="*80)

    # åŠ è½½æ•°æ®
    print(f"\nğŸ“– æ­£åœ¨åŠ è½½æ•°æ®: {INPUT_FILE}")
    with open(INPUT_FILE, 'r') as f:
        data_json = json.load(f)
    
    # é€‚é…æ–°æ•°æ®æ ¼å¼ï¼šä»detailed_resultsä¸­æå–æ•°æ®
    if isinstance(data_json, dict) and 'detailed_results' in data_json:
        data = data_json['detailed_results']
        print(f"   æ£€æµ‹åˆ°æ–°æ•°æ®æ ¼å¼ï¼Œä»detailed_resultsåŠ è½½")
    else:
        data = data_json
    
    total_images = len(data)
    total_relations = sum(len(img['relations']) for img in data)
    print(f"   åŠ è½½äº† {total_images} å¼ å›¾ç‰‡ï¼Œå…± {total_relations} ä¸ªå…³ç³»")
    
    #  åŠ è½½æ¨¡å‹
    print("\nğŸ”§ æ­£åœ¨åŠ è½½VLM2Vecæ¨¡å‹...")
    

    model_args = ModelArguments(
        model_name='/public/home/xiaojw2025/Workspace/VLM2Vec/models/qwen_vl/Qwen2-VL-2B-Instruct',
        # checkpoint_path='/public/home/xiaojw2025/Workspace/VLM2Vec/models/VLM2Vec-Qwen2VL-2B',
        checkpoint_path='/public/home/xiaojw2025/Workspace/VLM2Vec/models/final',
        pooling='last',
        normalize=True,
        model_backbone='qwen2_vl',
        lora=True
    )
    
    data_args = DataArguments(
        resize_min_pixels=56 * 56,
        resize_max_pixels=28 * 28 * 1280
    )
    
    processor = load_processor(model_args, data_args)
    
    # å°è¯•åŠ è½½æ¨¡å‹ï¼Œå¦‚æœflash attentionå¤±è´¥åˆ™é™çº§
    try:
        model = MMEBModel.load(model_args)
        model = model.to('cuda', dtype=torch.bfloat16)
        model.eval()
        print("   âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    except Exception as e:
        error_msg = str(e)
        # æ£€æŸ¥æ˜¯å¦æ˜¯Flash Attentionç›¸å…³é”™è¯¯
        if ("flash" in error_msg.lower() or 
            "ampere" in error_msg.lower() or 
            "attention" in error_msg.lower() and "support" in error_msg.lower()):
            print(f"\nâš ï¸  æ¨¡å‹åŠ è½½/è¿è¡Œå¤±è´¥: {error_msg[:200]}")
            print("   æ£€æµ‹åˆ°Flash Attentionå…¼å®¹æ€§é—®é¢˜")
            print("   å°è¯•é™çº§åˆ°eageræ¨¡å¼...")
            
            # å¼ºåˆ¶ä½¿ç”¨eageræ¨¡å¼ï¼ˆé€šè¿‡ç¯å¢ƒå˜é‡ï¼‰
            os.environ["ATTN_IMPLEMENTATION"] = "eager"
            os.environ["USE_FLASH_ATTENTION"] = "0"
            
            # éœ€è¦é‡æ–°å¯¼å…¥æ¨¡å—ä»¥åº”ç”¨æ–°çš„ç¯å¢ƒå˜é‡
            import importlib
            import src.model.model
            importlib.reload(src.model.model)
            from src.model.model import MMEBModel as MMEBModelReloaded
            
            try:
                # é‡æ–°åŠ è½½å¤„ç†å™¨å’Œæ¨¡å‹
                processor = load_processor(model_args, data_args)
                model = MMEBModelReloaded.load(model_args)
                model = model.to('cuda', dtype=torch.bfloat16)
                model.eval()
                print("   âœ… æ¨¡å‹åŠ è½½å®Œæˆ (ä½¿ç”¨eageræ¨¡å¼)")
            except Exception as e2:
                print(f"\nâŒ é™çº§åä»ç„¶å¤±è´¥: {e2}")
                raise
        else:
            print(f"\nâŒ æ¨¡å‹åŠ è½½å¤±è´¥: {error_msg}")
            raise
    
    # 3. é¢„è®¡ç®—è°“è¯å‘é‡ï¼ˆåªéœ€è¦ä¸€æ¬¡ï¼‰
    print("\nğŸš€ é¢„è®¡ç®—è°“è¯å‘é‡ï¼ˆåŠ é€Ÿæ¨ç†ï¼‰...\n")
    predicate_vectors = precompute_predicate_vectors(model, processor, PREDICATES)
    
    # 4. æ‰¹é‡é¢„æµ‹
    print("\nğŸš€ å¼€å§‹æ‰¹é‡é¢„æµ‹...\n")
    
    per_image_candidates = {}  # æŒ‰å›¾ç‰‡ç»„ç»‡çš„å€™é€‰é¢„æµ‹ {image_id: [candidates]}
    all_relations_info = []  # æ¯ä¸ªå…³ç³»çš„è¯¦ç»†ä¿¡æ¯
    
    global_relation_idx = 0  # å…¨å±€å…³ç³»ç´¢å¼•
    
    for img_idx, img_data in enumerate(tqdm(data, desc="å¤„ç†å›¾ç‰‡")):
        image_id = img_data['image_id']
        image_path = img_data['image_path']
        relations = img_data['relations']  # æ–°æ ¼å¼ä¸­ï¼Œrelationså·²ç»åŒ…å«æ‰€æœ‰é…å¯¹
        
        # åˆå§‹åŒ–è¯¥å›¾ç‰‡çš„å€™é€‰åˆ—è¡¨
        image_candidates = []
        image_relation_idx = 0  # è¯¥å›¾ç‰‡å†…çš„å…³ç³»ç´¢å¼•
        
        # åˆ›å»ºGTå…³ç³»æ˜ å°„ï¼Œç”¨äºåˆ¤æ–­é¢„æµ‹æ˜¯å¦æ­£ç¡®
        # æ³¨æ„ï¼šæ–°æ ¼å¼ä¸­å¯èƒ½æ²¡æœ‰GT predicateï¼Œåªæœ‰predictionæè¿°
        # å¦‚æœéœ€è¦GTï¼Œå¯èƒ½éœ€è¦ä»åŸå§‹æ•°æ®ä¸­è¯»å–ï¼Œæˆ–è€…å‡è®¾æ¯ä¸ªrelationéƒ½æœ‰ä¸€ä¸ªGT
        gt_relations_map = {}
        for relation in relations:
            subject_id = relation['subject_id']
            object_id = relation['object_id']
            # æ–°æ ¼å¼å¯èƒ½æ²¡æœ‰predicateå­—æ®µï¼Œåªæœ‰predictionæè¿°
            # å¦‚æœæœ‰predicateå­—æ®µåˆ™ä½¿ç”¨ï¼Œå¦åˆ™è·³è¿‡GTæ£€æŸ¥
            if 'predicate' in relation:
                gt_predicate = relation['predicate']
                if (subject_id, object_id) not in gt_relations_map:
                    gt_relations_map[(subject_id, object_id)] = []
                gt_relations_map[(subject_id, object_id)].append(gt_predicate)
        
        # éå†relationsä¸­çš„æ¯ä¸ªå…³ç³»é…å¯¹
        for relation in relations:
            subject_id = relation['subject_id']
            object_id = relation['object_id']
            subject_name = relation['subject_name']
            object_name = relation['object_name']
            query_text = relation['prediction']  # ä½¿ç”¨predictionä½œä¸ºquery
            
            # æ£€æŸ¥æ˜¯å¦æœ‰GT predicate
            has_gt = (subject_id, object_id) in gt_relations_map
            gt_predicates = gt_relations_map.get((subject_id, object_id), [])
            
            # ä½¿ç”¨predictionä½œä¸ºqueryï¼Œé¢„æµ‹50ä¸ªè°“è¯çš„ç›¸ä¼¼åº¦
            try:
                predicate_scores = predict_relation(
                    model, processor, query_text,
                    predicate_vectors=predicate_vectors  # ä¼ å…¥é¢„è®¡ç®—çš„å‘é‡
                )
            except Exception as e:
                print(f"âš ï¸  é¢„æµ‹å¤±è´¥ (image {image_id}, relation {subject_id}-{object_id}): {e}")
                continue
            
            # è®°å½•è¯¥å…³ç³»çš„ä¿¡æ¯ï¼ˆå¦‚æœæœ‰GTï¼‰
            if has_gt:
                for gt_predicate in gt_predicates:
                    all_relations_info.append({
                        'relation_idx': global_relation_idx,
                        'image_id': image_id,
                        'image_relation_idx': image_relation_idx,
                        'subject': subject_name,
                        'object': object_name,
                        'gt_predicate': gt_predicate
                    })
                    image_relation_idx += 1
                    global_relation_idx += 1
            
            # å°†è¯¥é…å¯¹çš„50ä¸ªè°“è¯å€™é€‰åŠ å…¥è¯¥å›¾ç‰‡çš„å€™é€‰æ± 
            for pred_score in predicate_scores:
                # åˆ¤æ–­é¢„æµ‹æ˜¯å¦æ­£ç¡®ï¼ˆå¦‚æœè¯¥é…å¯¹æœ‰GTå…³ç³»ï¼‰
                is_correct = False
                if has_gt and pred_score['predicate'] in gt_predicates:
                    is_correct = True
                
                image_candidates.append({
                    'relation_idx': image_relation_idx - len(gt_predicates) if has_gt else -1,
                    'global_relation_idx': global_relation_idx - len(gt_predicates) if has_gt else -1,
                    'image_id': image_id,
                    'subject': subject_name,
                    'object': object_name,
                    'gt_predicate': gt_predicates[0] if gt_predicates else None,
                    'gt_predicates': gt_predicates,
                    'predicted_predicate': pred_score['predicate'],
                    'similarity': pred_score['similarity'],
                    'is_correct': is_correct,
                    'has_gt': has_gt,
                    'query_text': query_text  # ä¿å­˜åŸå§‹queryæ–‡æœ¬
                })
        
        # ä¿å­˜è¯¥å›¾ç‰‡çš„æ‰€æœ‰å€™é€‰
        per_image_candidates[image_id] = image_candidates
    
    print(f"\nâœ… é¢„æµ‹å®Œæˆï¼")
    print(f"   æ€»å›¾ç‰‡æ•°: {len(per_image_candidates)}")
    print(f"   æ€»GTå…³ç³»æ•°: {len(all_relations_info)}")
    total_candidates = sum(len(candidates) for candidates in per_image_candidates.values())
    print(f"   æ€»å€™é€‰é¢„æµ‹æ•°: {total_candidates}")
    
    # ç»Ÿè®¡é…å¯¹ä¿¡æ¯
    total_pairs = 0
    total_gt_pairs = 0
    for candidates in per_image_candidates.values():
        pairs_in_image = set((cand['subject'], cand['object']) for cand in candidates)
        gt_pairs_in_image = set((cand['subject'], cand['object']) for cand in candidates if cand['has_gt'])
        total_pairs += len(pairs_in_image)
        total_gt_pairs += len(gt_pairs_in_image)
    
    print(f"   æ€»é¢„æµ‹é…å¯¹å¯¹æ•°: {total_pairs}")
    print(f"   æœ‰GTçš„é…å¯¹å¯¹æ•°: {total_gt_pairs}")
    print(f"   æ— GTçš„é…å¯¹å¯¹æ•°: {total_pairs - total_gt_pairs}")
    
    # 5. è®¡ç®—Per-Image Recall@50å¹¶å–å¹³å‡
    print("\nğŸ“Š è®¡ç®—Per-Image Recall@50ï¼ˆæ¯å¼ å›¾ç‰‡ç‹¬ç«‹è®¡ç®—å†å¹³å‡ï¼‰...")
    recall_results = calculate_average_recall_at_k(per_image_candidates, k=50)
    
    # 5.1 è®¡ç®—Mean Recall@50ï¼ˆé’ˆå¯¹æ¯ä¸ªè°“è¯ç±»åˆ«ï¼‰
    print("\nğŸ“Š è®¡ç®—Mean Recall@50ï¼ˆé’ˆå¯¹æ‰€æœ‰è°“è¯ç±»åˆ«ï¼‰...")
    mean_recall_results = calculate_mean_recall_per_predicate(per_image_candidates, PREDICATES, k=50)
    
    print("\n" + "="*80)
    print("è¯„ä¼°ç»“æœ (Per-Image Recall@50)")
    print("="*80)
    print(f"å¹³å‡ Recall@{recall_results['k']}: {recall_results['avg_recall@k']:.4f} ({recall_results['avg_recall@k']*100:.2f}%)")
    print(f"æ€»å›¾ç‰‡æ•°: {recall_results['total_images']}")
    print(f"æ€»å¬å›å…³ç³»æ•°: {recall_results['total_recalled_relations']}/{recall_results['total_gt_relations']}")
    
    # è®¡ç®—å¹³å‡é…å¯¹ç»Ÿè®¡
    avg_total_pairs = sum(r.get('total_pairs', 0) for r in recall_results['per_image_results']) / len(recall_results['per_image_results'])
    avg_gt_pairs = sum(r.get('gt_pairs', 0) for r in recall_results['per_image_results']) / len(recall_results['per_image_results'])
    avg_non_gt_pairs = sum(r.get('non_gt_pairs', 0) for r in recall_results['per_image_results']) / len(recall_results['per_image_results'])
    
    print(f"å¹³å‡æ¯å¼ å›¾ç‰‡é¢„æµ‹é…å¯¹å¯¹æ•°: {avg_total_pairs:.1f}")
    print(f"å¹³å‡æ¯å¼ å›¾ç‰‡æœ‰GTçš„é…å¯¹å¯¹æ•°: {avg_gt_pairs:.1f}")
    print(f"å¹³å‡æ¯å¼ å›¾ç‰‡æ— GTçš„é…å¯¹å¯¹æ•°: {avg_non_gt_pairs:.1f}")
    
    if recall_results['images_with_insufficient_candidates'] > 0:
        print(f"å€™é€‰æ•°ä¸è¶³{recall_results['k']}çš„å›¾ç‰‡: {recall_results['images_with_insufficient_candidates']}/{recall_results['total_images']}")
    print("="*80)
    
    print("\n" + "="*80)
    print("è¯„ä¼°ç»“æœ (Mean Recall@50 - æ‰€æœ‰è°“è¯ç±»åˆ«)")
    print("="*80)
    print(f"Mean Recall@{mean_recall_results['k']}: {mean_recall_results['mean_recall@k']:.4f} ({mean_recall_results['mean_recall@k']*100:.2f}%)")
    print(f"æœ‰æ•ˆè°“è¯ç±»åˆ«æ•°: {mean_recall_results['num_valid_predicates']}/{mean_recall_results['total_predicates']}")
    print("="*80)
    
    # æ˜¾ç¤ºæ¯ä¸ªè°“è¯çš„recallï¼ˆå‰10ä¸ªå’Œå10ä¸ªï¼‰
    print("\nè°“è¯ç±»åˆ«Recallè¯¦æƒ…ï¼ˆæŒ‰recallæ’åºï¼‰:")
    sorted_predicates = sorted(
        mean_recall_results['per_predicate_recall'].items(),
        key=lambda x: x[1]['recall'],
        reverse=True
    )
    
    # åªæ˜¾ç¤ºæœ‰GTçš„è°“è¯
    predicates_with_gt = [(pred, stats) for pred, stats in sorted_predicates if stats['total'] > 0]
    
    if len(predicates_with_gt) > 0:
        print("\n  Top-10 è¡¨ç°æœ€å¥½çš„è°“è¯:")
        for i, (pred, stats) in enumerate(predicates_with_gt[:10], 1):
            print(f"    {i:2d}. {pred:20s}: R={stats['recall']:.4f} ({stats['hit']:3d}/{stats['total']:3d})")
        
        if len(predicates_with_gt) > 10:
            print("\n  Bottom-10 è¡¨ç°æœ€å·®çš„è°“è¯:")
            for i, (pred, stats) in enumerate(predicates_with_gt[-10:], 1):
                print(f"    {i:2d}. {pred:20s}: R={stats['recall']:.4f} ({stats['hit']:3d}/{stats['total']:3d})")
    
    # 6. æ˜¾ç¤ºæ¯å¼ å›¾ç‰‡çš„recallåˆ†å¸ƒ
    per_image_recalls = [r['recall@k'] for r in recall_results['per_image_results']]
    if per_image_recalls:
        print(f"\nRecallåˆ†å¸ƒç»Ÿè®¡:")
        print(f"  æœ€å¤§å€¼: {max(per_image_recalls):.4f}")
        print(f"  æœ€å°å€¼: {min(per_image_recalls):.4f}")
        print(f"  ä¸­ä½æ•°: {sorted(per_image_recalls)[len(per_image_recalls)//2]:.4f}")
    
    # 7. æ”¶é›†æ‰€æœ‰å€™é€‰ç”¨äºå±•ç¤ºï¼ˆå¯é€‰ï¼‰
    all_candidate_predictions = []
    for candidates in per_image_candidates.values():
        all_candidate_predictions.extend(candidates)
    
    candidates_sorted = sorted(all_candidate_predictions, key=lambda x: x['similarity'], reverse=True)
    top50_global_candidates = candidates_sorted[:100]
    
    # 7.1 ä¸ºæ¯å¼ å›¾ç‰‡æ”¶é›†Top-100å€™é€‰ç»“æœ
    print("\nğŸ“¦ æ­£åœ¨æ•´ç†æ¯å¼ å›¾ç‰‡çš„Top-100å€™é€‰ç»“æœ...")
    per_image_top100_candidates = {}
    total_top100_candidates = 0
    
    for image_id, candidates in per_image_candidates.items():
        # æŒ‰ç›¸ä¼¼åº¦æ’åº
        sorted_candidates = sorted(candidates, key=lambda x: x['similarity'], reverse=True)
        # å–Top-100
        top100 = sorted_candidates[:min(100, len(sorted_candidates))]
        per_image_top100_candidates[image_id] = top100
        total_top100_candidates += len(top100)
    
    print(f"   æ”¶é›†äº† {len(per_image_top100_candidates)} å¼ å›¾ç‰‡çš„Top-100å€™é€‰")
    print(f"   æ€»å€™é€‰æ•°: {total_top100_candidates}")
    
    # 8. ä¿å­˜ç»“æœ
    print(f"\nğŸ’¾ æ­£åœ¨ä¿å­˜ç»“æœåˆ°: {OUTPUT_FILE}")
    output_data = {
        'summary': {
            'evaluation_method': 'per-image-all-pairs',
            'total_images': len(per_image_candidates),
            'total_gt_relations': len(all_relations_info),
            'total_candidates': total_candidates,
            'total_top100_candidates': total_top100_candidates,  # æ–°å¢ï¼šTop-100å€™é€‰æ€»æ•°
            'avg_recall@50': recall_results['avg_recall@k'],
            'mean_recall@50': mean_recall_results['mean_recall@k'],
            'total_recalled_relations': recall_results['total_recalled_relations'],
            'total_gt_relations': recall_results['total_gt_relations'],
            'num_valid_predicates': mean_recall_results['num_valid_predicates'],
            'images_with_insufficient_candidates': recall_results['images_with_insufficient_candidates'],
            # æ–°å¢é…å¯¹ç»Ÿè®¡
            'total_pairs': total_pairs,
            'total_gt_pairs': total_gt_pairs,
            'total_non_gt_pairs': total_pairs - total_gt_pairs,
            'avg_pairs_per_image': total_pairs / len(per_image_candidates) if len(per_image_candidates) > 0 else 0,
            'avg_gt_pairs_per_image': total_gt_pairs / len(per_image_candidates) if len(per_image_candidates) > 0 else 0
        },
        'per_image_results': recall_results['per_image_results'],
        'mean_recall_per_predicate': mean_recall_results['per_predicate_recall'],
        'all_relations': all_relations_info,
        'per_image_top100_candidates': per_image_top100_candidates,  # æ–°å¢ï¼šæ¯å¼ å›¾ç‰‡çš„Top-100å€™é€‰
        'top50_global_candidates': top50_global_candidates,  # å…¨å±€æ’åºçš„top50ï¼ˆå‚è€ƒç”¨ï¼‰
        # 'all_candidates': all_candidate_predictions  # å®Œæ•´çš„å€™é€‰åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œå¯èƒ½å¾ˆå¤§ï¼‰
    }
    
    os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)
    
    print("âœ… ç»“æœå·²ä¿å­˜ï¼")
    
    # 9. æ˜¾ç¤ºä¸€äº›æ ·ä¾‹
    print("\n" + "="*80)
    print("Per-Image Recallæ ·ä¾‹ï¼ˆå‰5å¼ å›¾ç‰‡ï¼‰")
    print("="*80)
    for i, img_result in enumerate(recall_results['per_image_results'][:5], 1):
        print(f"\n{i}. å›¾ç‰‡#{img_result['image_id']}")
        print(f"   Recall@50: {img_result['recall@k']:.4f} ({img_result['recall@k']*100:.2f}%)")
        print(f"   å¬å›: {img_result['recalled_relations']}/{img_result['total_gt_relations']} å…³ç³»")
        actual_k_info = f" (å®é™…å–{img_result['actual_k']}ä¸ª)" if img_result['actual_k'] < img_result['k'] else ""
        print(f"   å€™é€‰æ•°: {img_result['total_candidates']} (Top-{img_result['k']}ä¸­å–{img_result['top_k_candidates']}ä¸ª{actual_k_info})")
        print(f"   é…å¯¹ç»Ÿè®¡: æ€»é…å¯¹{img_result.get('total_pairs', 0)}å¯¹, æœ‰GTé…å¯¹{img_result.get('gt_pairs', 0)}å¯¹, æ— GTé…å¯¹{img_result.get('non_gt_pairs', 0)}å¯¹")
    
    print("\n" + "="*80)
    print("å…¨å±€Top-50å€™é€‰é¢„æµ‹æ ·ä¾‹ï¼ˆå‰10ä¸ªï¼Œä»…ä¾›å‚è€ƒï¼‰")
    print("="*80)
    for i, pred in enumerate(top50_global_candidates[:10], 1):
        status = "âœ…" if pred['is_correct'] else "âŒ"
        print(f"\n{i}. {status} æ’å#{i} (ç›¸ä¼¼åº¦: {pred['similarity']:.4f})")
        print(f"   å›¾ç‰‡#{pred['image_id']}, å…³ç³»#{pred['relation_idx']}: {pred['subject']} --[{pred['predicted_predicate']}]--> {pred['object']}")
        print(f"   GTè°“è¯: {pred['gt_predicate']}")


if __name__ == "__main__":
    main()

